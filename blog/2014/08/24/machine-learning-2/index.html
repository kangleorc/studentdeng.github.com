
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>机器学习(二) 线性回归、梯度下降实现 - 不会开机的男孩</title>
  <meta name="author" content="studentdeng">

  
  <meta name="description" content="了解一个算法最好的方法就是实现它，不过在开始实现算法之前，有一些额外的概念需要理解。 Vectorization 这是上一篇提到的hypothesis的计算公式。 当计算这个表达式值的时候，往往第一个感觉是写一个for loop 然后累加求和 prediction = 0;
for (int i &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://studentdeng.github.com/blog/2014/08/24/machine-learning-2">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="不会开机的男孩" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/jquery.min1.9.1.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/lib/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
  

</head>

<body   class="collapse-sidebar sidebar-footer" >
  <header role="banner"><hgroup>
  <h1><a href="/">不会开机的男孩</a></h1>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:studentdeng.github.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  	<li><a href="/">Blog</a></li>
  	<li><a href="/blog/archives">Archives</a></li>
	 <li><a href="/tags/index.html">Tags</a></li>
	<li><a href="/favorite/index.html">Favorite</a></li>
	<li><a href="/about/index.html">About</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">机器学习(二) 线性回归、梯度下降实现</h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-08-24T20:52:00+08:00" pubdate data-updated="true">Aug 24<span>th</span>, 2014</time>
        
         | <a href="#disqus_thread">Comments</a>
        
      </p>
    
  </header>


<div class="entry-content"><p>了解一个算法最好的方法就是实现它，不过在开始实现算法之前，有一些额外的概念需要理解。</p>

<h1>Vectorization</h1>

<p>这是<a href="http://studentdeng.github.io/blog/2014/07/28/machine-learning-tutorial/">上一篇</a>提到的hypothesis的计算公式。</p>

<p><span class='caption-wrapper'><img class='caption' src='/images/ml2_1.png' width='' height='' title=''><span class='caption-text'></span></span></p>

<p>当计算这个表达式值的时候，往往第一个感觉是写一个for loop 然后累加求和</p>

<pre><code>prediction = 0;
for (int i = 0; i &lt; n; ++i) {
    prediction += theta[j] * x[j];
}
</code></pre>

<p>但是在machine learning中更倾向于使用矩阵的方式。
比如同样的公式，会看成矩阵相乘。</p>

<p><span class='caption-wrapper'><img class='caption' src='/images/ml2_3.png' width='' height='' title=''><span class='caption-text'></span></span></p>

<p>其中theta和X分别是</p>

<p><span class='caption-wrapper'><img class='caption' src='/images/ml2_2.png' width='' height='' title=''><span class='caption-text'></span></span></p>

<p>这里通过矩阵或是向量来代替之前的loop。</p>

<p>这是<a href="http://studentdeng.github.io/blog/2014/07/28/machine-learning-tutorial/">上一篇</a>提到的算法</p>

<p><img src="http://studentdeng.github.io/images/ml/4.png" alt="image" /></p>

<p>计算function J如果用octave来实现则是这个样子</p>

<pre><code>function J = computeCost(X, y, theta)
%COMPUTECOST Compute cost for linear regression
%   J = COMPUTECOST(X, y, theta) computes the cost of using theta as the
%   parameter for linear regression to fit the data points in X and y

% Initialize some useful values
m = length(y); % number of training examples

% You need to return the following variables correctly 
J = 0;

% ====================== YOUR CODE HERE ======================
% Instructions: Compute the cost of a particular choice of theta
%               You should set J to the cost.


t = (X * theta) - y;
J = (sum(t .* t)) / (2 * m);

% =========================================================================

end
</code></pre>

<p><img src="http://studentdeng.github.io/images/ml/19.png" alt="image" /></p>

<p>而求偏导数迭代更新theta的代码则是这个样子</p>

<pre><code>function [theta, J_history] = gradientDescent(X, y, theta, alpha, num_iters)
%GRADIENTDESCENT Performs gradient descent to learn theta
%   theta = GRADIENTDESENT(X, y, theta, alpha, num_iters) updates theta by 
%   taking num_iters gradient steps with learning rate alpha

% Initialize some useful values
m = length(y); % number of training examples
J_history = zeros(num_iters, 1);

for iter = 1:num_iters

    % ====================== YOUR CODE HERE ======================
    % Instructions: Perform a single gradient step on the parameter vector
    %               theta. 
    %
    % Hint: While debugging, it can be useful to print out the values
    %       of the cost function (computeCost) and gradient here.
    %


    s = sum(bsxfun(@times, X * theta - y, X));
    theta = theta - (alpha / m) * s';

    % ============================================================

    % Save the cost J in every iteration    
    J_history(iter) = computeCost(X, y, theta);

end
</code></pre>

<p>上面的2部分代码如果做一些合并分别可以简化成1行代码。说到这里自己还是相当羞愧的。今天早上花了3个小时才搞定这2行代码&#8230;主要时间花在了
2个地方。</p>

<ol>
<li>算好theta去predict的上面，和normal equations的方式计算的答案总是对不上，不得不怀疑人生了。。。后面才发现是因为函数没有完全收敛，在调整learning rate之后误差明显变小了。</li>
<li>让大脑适应矩阵还是有点难，很多东西看上去很简单，反应很长时间，不过后面会好一些。</li>
</ol>


<h1>为什么用矩阵</h1>

<p>在费了老半天力气搞定Vectorization的转变之后，不得不想想为什么要用这个方式做。obviously有2个好处，Andrew课上也提到了好多次。</p>

<ol>
<li>增加一个feature很简单，只要把输入增加一列就好，而算法不需要改动。</li>
<li>矩阵的运算更容易优化，性能比循环更快。实际我们往往处理上百万个Example和N多的features</li>
</ol>


<p>第一个很好理解，而且把循环的一大堆代码写成一行，显得逼格很高。
第二个会比较麻烦，涉及到了并行计算优化。</p>

<h1>其他</h1>

<p>在之前的算法中，我们看到了每一次调整theta都需要iterate整个所有的example，但实际中往往需要处理上百万个examples，而这样的iteration显然是不能接受的。实际上会随机选取一部分examples然后去迭代theta，最后得到一个较为可靠的theta向量。</p>

<p>最后附上Andrew作业的图片，虽然Andrew 不希望把答案放在网上或是论坛什么的，不过我觉得都过去2年多了,应该没关系了。</p>

<p><span class='caption-wrapper'><img class='caption' src='/images/ml2_4.png' width='' height='' title='最后的预测效果图'><span class='caption-text'>最后的预测效果图</span></span></p>

<p><span class='caption-wrapper'><img class='caption' src='/images/ml2_5.png' width='' height='' title='cost function & theta'><span class='caption-text'>cost function &amp; theta</span></span></p>

<p><span class='caption-wrapper'><img class='caption' src='/images/ml2_6.png' width='' height='' title='cost function & theta 等高线'><span class='caption-text'>cost function &amp; theta 等高线</span></span></p>

<p><span class='caption-wrapper'><img class='caption' src='/images/ml2_7.png' width='' height='' title='learning rate'><span class='caption-text'>learning rate</span></span></p>
</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">studentdeng</span></span>

      








  


<time datetime="2014-08-24T20:52:00+08:00" pubdate data-updated="true">Aug 24<span>th</span>, 2014</time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/algorithms/'>algorithms</a>, <a class='category' href='/blog/categories/ji-qi-xue-xi/'>机器学习</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2014/08/16/qinshihuang/" title="Previous Post: 《中国古代历史与人物——秦始皇》笔记">&laquo; 《中国古代历史与人物——秦始皇》笔记</a>
      
      
    </p>
  </footer>
</article>

  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
  </section>


</div>

<aside class="sidebar">
  
    
  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 - studentdeng -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a> | Themed with <a href="https://github.com/lucaslew/whitespace">Whitespace</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'studentdeng';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://studentdeng.github.com/blog/2014/08/24/machine-learning-2/';
        var disqus_url = 'http://studentdeng.github.com/blog/2014/08/24/machine-learning-2/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>








</body>
</html>
