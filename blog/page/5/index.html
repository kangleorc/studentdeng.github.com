
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>studentdeng Blog</title>
  <meta name="author" content="studentdeng">

  
  <meta name="description" content="之前一直做C++开发，最近2个多月转 Objective-C， 入门的时候，遇到了很多的困惑。现在过节，正是解决他们的好时机。 主要参考来自http://www.sealiesoftware.com/blog/archive/2009/04/14/ &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://studentdeng.github.com/blog/page/5/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="studentdeng Blog" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">studentdeng Blog</a></h1>
  
    <h2>不会开机的男孩</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:studentdeng.github.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/about">About</a></li>
  <li><a href="/favorite">favorite</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/10/05/objcclass/">Objcclass</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-10-05T23:31:00+08:00" pubdate data-updated="true">Oct 5<span>th</span>, 2011</time>
        

        
      | <a href="/blog/2011/10/05/objcclass/#comments">Comments</a>
        

      </p>
    
  </header>


  <div class="entry-content"><p>之前一直做C++开发，最近2个多月转 Objective-C， 入门的时候，遇到了很多的困惑。现在过节，正是解决他们的好时机。</p>

<p>主要参考来自http://www.sealiesoftware.com/blog/archive/2009/04/14/objc_explain_Classes_and_metaclasses.html</p>

<p> Objective-C 也是面向对象的语言，那么，首先需要知道的就是什么是class。</p>

<p>C++ 的class相对 Objective-C 中的class，就简单明了很多了。C++ 中class简单的说，就是一个大的struct， 绝大部分的class可以在编译时决定好class的布局（通过虚继承来的class成员变量只能动态确定）。当然，最关键的是，你不可能在运行时创建一个class，因为所有的class在运行之前已经确定下来，并保存在二进制文件中。</p>

<p>但是， Objective-C 确不同， Objective-C 可以在运行中创建class，修改class等等。那么，改如何定义 Objective-C 中的class呢。</p>

<p>在这之前，我们先看一个简单的，class的实例对象。</p>

<pre><code>@interface Object 
{

    //typedef struct objc_class *Class; 
    Class isa;    /* A pointer to the instance's class structure */ 
}
</code></pre>

<p>对象包含一个指向class的指针，而这也就意味着，任何包含class 的指针都可以被看做是对象（object）。</p>

<pre><code>struct objc_class {            
    struct objc_class *isa;    //这里也有isa指针 
    struct objc_class *super_class;    //这里还有一个指向基类的指针 
    const char *name;        
    long version; 
    long info; 
    long instance_size; 
    struct objc_ivar_list *ivars;

    struct objc_method_list **methodLists;

    struct objc_cache *cache; 
     struct objc_protocol_list *protocols; 
};

//新的定义
typedef struct class_t {

    struct class_t *isa;

    struct class_t *superclass;

    Cache cache;

    IMP *vtable;

    class_rw_t *data;

} class_t;
</code></pre>

<p>显然，在 Objective-C 眼中，一切都是对象，甚至包括我们的class。而对象就是class的实例，那么，class是什么的实例呢，metaclass。</p>

<p>事实上，我们并没有解决问题。metaclass 事实上又是root metaclass 的实例，而root metaclass 自己又是 root metaclass 的实例，一图胜千言，不做赘述。</p>

<p><img src="/images/objc.png" alt="alt text" /></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/08/26/hash/">Hash</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-08-26T23:28:00+08:00" pubdate data-updated="true">Aug 26<span>th</span>, 2011</time>
        

        
      | <a href="/blog/2011/08/26/hash/#comments">Comments</a>
        

      </p>
    
  </header>


  <div class="entry-content"><p>在应用程序中，常常需要将一个集合U（键值集合）和另一个集合T（数据集合）建立关系构造dictionary结构，来达到增删查改的需求。如果键值集合很小，那么可以直接采用Direct-address tables的方式实现。</p>

<p>假如我们的集合 U = {0, 1, &#8230;, m - 1}, 而且m并不大。如果我们的键和值对应唯一，那么我们可以通过构造一个大的数组来保存集合U，如下结构。</p>

<p><img src="/images/hash-1.png" alt="alt text" /></p>

<p>显然，当集合U增大，那么直接存储集合U变的不那么明智起来，而且，如果使用键的集合K变小是，我们浪费的空间也越来越大。当集合K比集合U小很多的时候，就是hash粉墨登场的时候了。hash将保存空间压缩到集合K的大小，并且控制查找元素的时间仍在O(1) 在平均情况下。</p>

<p>hash 通过hash函数h，将集合U 映射到hash表T[0,…, m-1]中， 即 h : U → {0, 1, &#8230;, m - 1}。显然，由于集合大小的限制，很可能造成有相同的key 指向了hash表中的同一项，如图。</p>

<p><img src="/images/hash-2.png" alt="alt text" /></p>

<p>我们将这一情况称为碰撞（Collision），解决碰撞的方法很多，最容易想到的是通过链表来保存碰撞的key。</p>

<p><img src="/images/hash-3.png" alt="alt text" /></p>

<p>一个简单的例子，linux2.4 在处理进程中，需要一个通过pid找到进程的要求，而具体实现则是利用了hash。在处理冲突时，采用的是链表的方法。不过由于是操作系统的代码，所以这里并不是通常意义的双向链表，pidhash_next 指向后一个进程，但是pidhash_pprev指向的是前一个进程的pidhash_next的地址。虽然不长，但是理解这段还是需要稍微动下脑筋，系统之所以这么实现，似乎是能够提高增加和删除时链表的效率。</p>

<pre><code>/* PID hashing. (shouldnt this be dynamic?) */ 
#define PIDHASH_SZ (4096 &gt;&gt; 2) 
extern struct task_struct *pidhash[PIDHASH_SZ]; 
#define pid_hashfn(x) ((((x) &gt;&gt; 8) ^ (x)) &amp; (PIDHASH_SZ - 1)) 

static inline void hash_pid(struct task_struct *p) 
{ 
    struct task_struct **htable = &amp;pidhash[pid_hashfn(p-&gt;pid)]; 
    if((p-&gt;pidhash_next = *htable) != NULL)//如果发生的冲突 
        (*htable)-&gt;pidhash_pprev = &amp;p-&gt;pidhash_next;//这里可以看出，pprev是上一个进程的next指针的地址 
    *htable = p; 
    p-&gt;pidhash_pprev = htable;//新的进程的pprev是指向了hash表项中的自己的地址 
} 
static inline void unhash_pid(struct task_struct *p) 
{ 
    if(p-&gt;pidhash_next)//如果有冲突 
        p-&gt;pidhash_next-&gt;pidhash_pprev = p-&gt;pidhash_pprev; 
    *p-&gt;pidhash_pprev = p-&gt;pidhash_next;//当没有冲突时，就会置NULL 
} 
static inline struct task_struct *find_task_by_pid(int pid) 
{ 
    struct task_struct *p, **htable = &amp;pidhash[pid_hashfn(pid)]; 
    for(p = *htable; p &amp;&amp; p-&gt;pid != pid; p = p-&gt;pidhash_next); 
    return p; 
}
</code></pre>

<p>SGI STL的例子 hash</p>

<p>SGI STL中的hashtable 同样采用的是开链法设计，这里就是hashtable中节点的样子</p>

<pre><code>template &lt;class _Val&gt; 
struct _Hashtable_node 
{ 
    _Hashtable_node* _M_next; 
    _Val _M_val; 
};
</code></pre>

<p>这里可以看出，hashtable并没有利用现有的list等容器，而是自己简单的创建一个单向链表并维护。由于hashtable中的每一项元素都是一连串的数据（处理冲突而在一个链表中），所以将hashtable中的元素成为bucket，表示这个元素其实可能有“一桶子”东西，最后hashtable通过vector管理bucket，实现动态增长。</p>

<p>同之前一样，首先从iterator开始了解。下面是hashtable的iterator实现。</p>

<pre><code>template &lt;class _Val, class _Key, class _HashFcn,
          class _ExtractKey, class _EqualKey, class _Alloc&gt;
struct _Hashtable_iterator {
  typedef hashtable&lt;_Val,_Key,_HashFcn,_ExtractKey,_EqualKey,_Alloc&gt;
          _Hashtable;
  typedef _Hashtable_iterator&lt;_Val, _Key, _HashFcn, 
                              _ExtractKey, _EqualKey, _Alloc&gt;
          iterator;
  typedef _Hashtable_const_iterator&lt;_Val, _Key, _HashFcn, 
                                    _ExtractKey, _EqualKey, _Alloc&gt;
          const_iterator;
  typedef _Hashtable_node&lt;_Val&gt; _Node;
  typedef forward_iterator_tag iterator_category; 
  typedef _Val value_type;
  typedef ptrdiff_t difference_type;
  typedef size_t size_type;
  typedef _Val&amp; reference;
  typedef _Val* pointer;
  _Node* _M_cur;         //指向当前的节点
  _Hashtable* _M_ht;     //指向hashtable容器
  _Hashtable_iterator(_Node* __n, _Hashtable* __tab) 
    : _M_cur(__n), _M_ht(__tab) {}
  _Hashtable_iterator() {}
  reference operator*() const { return _M_cur-&gt;_M_val; }
#ifndef __SGI_STL_NO_ARROW_OPERATOR
  pointer operator-&gt;() const { return &amp;(operator*()); }
#endif /* __SGI_STL_NO_ARROW_OPERATOR */
  iterator&amp; operator++();
  iterator operator++(int);
  bool operator==(const iterator&amp; __it) const
    { return _M_cur == __it._M_cur; }
  bool operator!=(const iterator&amp; __it) const
    { return _M_cur != __it._M_cur; }
};
</code></pre>

<p>可以看出，这里的迭代器设计成只能向后移动，在operator ++ 中，我们可以看到迭代器的移动。</p>

<pre><code>template &lt;class _Val, class _Key, class _HF, class _ExK, class _EqK, 
class _All&gt;
_Hashtable_iterator&lt;_Val,_Key,_HF,_ExK,_EqK,_All&gt;&amp;
_Hashtable_iterator&lt;_Val,_Key,_HF,_ExK,_EqK,_All&gt;::operator++()
{
    const _Node* __old = _M_cur;
    _M_cur = _M_cur-&gt;_M_next;
    if (!_M_cur) {
        size_type __bucket = _M_ht-&gt;_M_bkt_num(__old-&gt;_M_val);
        while (!_M_cur &amp;&amp; ++__bucket &lt; _M_ht-&gt;_M_buckets.size())
           _M_cur = _M_ht-&gt;_M_buckets[__bucket];
     }
     return *this;
}
</code></pre>

<p>首先在链表（一个bucket）中寻找下一个节点，如果是链表中的最后一个节点，那么寻找下一个链表（bucket）中的节点。了解迭代器之后，开始了解容器本身。</p>

<p>之前可以看出，SGI STL 虽然采用的是开链法，但是在分配空间大小时，依然采用的是质数，这一点和.net framework 中的dictionary一样。大小差不多是2倍</p>

<pre><code>static const int __stl_num_primes = 28;
static const unsigned long __stl_prime_list[__stl_num_primes] =
{
  53ul,         97ul,         193ul,       389ul,       769ul,
  1543ul,       3079ul,       6151ul,      12289ul,     24593ul,
  49157ul,      98317ul,      196613ul,    393241ul,    786433ul,
  1572869ul,    3145739ul,    6291469ul,   12582917ul,  25165843ul,
  50331653ul,   100663319ul,  201326611ul, 402653189ul, 805306457ul, 
  1610612741ul, 3221225473ul, 4294967291ul
};
//找到下一个大于n的质数，lower_bound是一个二分法查找。
inline unsigned long __stl_next_prime(unsigned long __n)
{
  const unsigned long* __first = __stl_prime_list;
  const unsigned long* __last = __stl_prime_list + __stl_num_primes;
  const unsigned long* pos = lower_bound(__first, __last, __n);
  return pos == __last ? *(__last - 1) : *pos;
}
</code></pre>

<p>  hashTable 中最重要的部分是扩容。那么，我们看看，SGI STL是怎么做的</p>

<pre><code>pair&lt;iterator, bool&gt; insert_unique(const value_type&amp; __obj) 
{ 
  resize(_M_num_elements + 1); 
  return insert_unique_noresize(__obj); 
}

template &lt;class _Val, class _Key, class _HF, class _Ex, class _Eq, class _All&gt;
void hashtable&lt;_Val,_Key,_HF,_Ex,_Eq,_All&gt;
  ::resize(size_type __num_elements_hint)
{
  const size_type __old_n = _M_buckets.size();
  if (__num_elements_hint &gt; __old_n) {
    //如果需要扩容，我们找到下一个质数
    const size_type __n = _M_next_size(__num_elements_hint);
    if (__n &gt; __old_n) {
      //搞一个新的buckets
      vector&lt;_Node*, _All&gt; __tmp(__n, (_Node*)(0),
                                 _M_buckets.get_allocator());
      __STL_TRY {
        for (size_type __bucket = 0; __bucket &lt; __old_n; ++__bucket) {
          //遍历之旧的buckets
          _Node* __first = _M_buckets[__bucket];
          while (__first) {
            //遍历旧的bucket，这里，我们根据新的大小找到了新的位置
            size_type __new_bucket = _M_bkt_num(__first-&gt;_M_val, __n);
            //将旧的bucket数据改为 我们正在处理的item的下一个 
            _M_buckets[__bucket] = __first-&gt;_M_next;
            //把我们现在处理的item 插入到新的buckets中。
            __first-&gt;_M_next = __tmp[__new_bucket];
            __tmp[__new_bucket] = __first;
            //将我们当前处理的item，修改为旧数据的下一个
            __first = _M_buckets[__bucket];          
          }
        }
        //都搞定了，我们将buckets更换。
        _M_buckets.swap(__tmp);
      }
#ifdef __STL_USE_EXCEPTIONS
      catch(...) {
        for (size_type __bucket = 0; __bucket &lt; __tmp.size(); ++__bucket) {
          while (__tmp[__bucket]) {
            _Node* __next = __tmp[__bucket]-&gt;_M_next;
            _M_delete_node(__tmp[__bucket]);
            __tmp[__bucket] = __next;
          }
        }
        throw;
      }
#endif /* __STL_USE_EXCEPTIONS */
    }
  }
}
</code></pre>

<p>当然，这个只是insert_unique ，insert_equal 类似，这里不做描述。</p>

<p>除了resize，hashtable中还有一个吸引我们的就是hash func。但是，一般我们并不会指定hash func， 那么，我们看看SGI STL 是如何选择hash 函数的。</p>

<pre><code>#ifndef __SGI_STL_HASH_FUN_H
#define __SGI_STL_HASH_FUN_H
#include &lt;stddef.h&gt;
__STL_BEGIN_NAMESPACE
template &lt;class _Key&gt; struct hash { };
//字符串这里看来稍微有了一些操作
inline size_t __stl_hash_string(const char* __s)
{
  unsigned long __h = 0; 
  for ( ; *__s; ++__s)
    __h = 5*__h + *__s;

  return size_t(__h);
}
//这些东西，通过c++ 模板偏特化实现，我们看到，这些东西，啥都没做，只是返回而已。所以，如果
//希望获得最佳的性能，实现仿函数。是非常必要的。
__STL_TEMPLATE_NULL struct hash&lt;char*&gt;
{
  size_t operator()(const char* __s) const { return __stl_hash_string(__s); }
};
__STL_TEMPLATE_NULL struct hash&lt;const char*&gt;
{
  size_t operator()(const char* __s) const { return __stl_hash_string(__s); }
};
__STL_TEMPLATE_NULL struct hash&lt;char&gt; {
  size_t operator()(char __x) const { return __x; }
};
__STL_TEMPLATE_NULL struct hash&lt;unsigned char&gt; {
  size_t operator()(unsigned char __x) const { return __x; }
};
__STL_TEMPLATE_NULL struct hash&lt;signed char&gt; {
  size_t operator()(unsigned char __x) const { return __x; }
};
__STL_TEMPLATE_NULL struct hash&lt;short&gt; {
  size_t operator()(short __x) const { return __x; }
};
__STL_TEMPLATE_NULL struct hash&lt;unsigned short&gt; {
  size_t operator()(unsigned short __x) const { return __x; }
};
__STL_TEMPLATE_NULL struct hash&lt;int&gt; {
  size_t operator()(int __x) const { return __x; }
};
__STL_TEMPLATE_NULL struct hash&lt;unsigned int&gt; {
  size_t operator()(unsigned int __x) const { return __x; }
};
__STL_TEMPLATE_NULL struct hash&lt;long&gt; {
  size_t operator()(long __x) const { return __x; }
};
__STL_TEMPLATE_NULL struct hash&lt;unsigned long&gt; {
  size_t operator()(unsigned long __x) const { return __x; }
};
</code></pre>

<p>SQLite 的hash表。</p>

<p>SQLite是在移动设备上普遍的一个家伙， 他用到了2种HASH， 一种和上面的SGI STL 类似，在PC端，在做增加的时候，判断了数据量大小（一般10个），如果小于，则采用双向链表的方式，不是则采用hash存储。只是，在移动分支中我没有找到，PC端的确有这样的设计，也许在mobile上做了精简。这种hash，用于SQLite底层的内存管理，缓存部分，SQLite采用的是LRU的方式缓存。</p>

<p>另一种Hash是叫做perfect hash。这是一种在最坏情况下，依然能够达到O(1) 的能力，听上去似乎挺吓人的，但是大多数是指固定的表，当然，似乎有些能够做到动态保证，不过，不管他了，我可不是科学家。</p>

<p>SQLite 的前端是需要做词法语法分析的。这部分就涉及到了关键字的保存，这里SQLite 通过perfect hash来达到快速查找。具体的策略了解编译原理的都比较明白，但是，这个的确比较有意思。</p>

<p>构造关键字是通过一个起始位置和长度来获取的。如 “REINDEX 、 INDEXED 、 INDEX 、 DESC”；将保存成“REINDEXEDESC”。那么 REINDEX = （0， 7）。而剩下的工作可以交给一些程序，他们会帮助我们生成perfect hash。</p>

<p>大数据量下，hash信息指纹的应用。可以参考 google黑板报  http://www.google.com.hk/ggblog/googlechinablog/2006/08/blog-post_8115.html</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/03/31/sendthreadmessage/">为什么没有SendThreadMessage呢？</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-03-31T23:24:00+08:00" pubdate data-updated="true">Mar 31<span>st</span>, 2011</time>
        

        
      | <a href="/blog/2011/03/31/sendthreadmessage/#comments">Comments</a>
        

      </p>
    
  </header>


  <div class="entry-content"><p>最近忙公司的项目（或是毕设吧），发现很长时间没有总结了。是该换换脑子了。</p>

<p>“为什么没有SendThreadMessage呢？”这个问题，就来自自己平时实现的一些程序逻辑中。在一些具体的场景中，对像我这样的初学者来说，往往喜欢通过windwos的消息机制来完成UI线程和worker线程之间的同步，而不是去通过信号量或其他的去做。所以，这个问题一直困惑了自己很久。而现在，就来搞明白这个、</p>

<p>google一下，这个问题，在一个大牛（Raymond Chen）http://blogs.msdn.com/b/oldnewthing/archive/2008/12/23/9248851.aspx）的博客中提到了，而且也引发了很多讨论。我这里简单的”翻译”一下Raymond Chen自己的看法。</p>

<p>”想象中的SendThreadMessage是如何工作的呢？调用SendMessage 把消息直接分发给窗口过程？但是我们没有看到消息泵，想象中的SendThreadMessage将会把消息分发给谁呢？因为我们没有‘thread window procedure’这样的东东去处理我们的消息。</p>

<p>是的，我们可以自己在我们的线程中做一个消息泵，但是，想象中的SendThreadMessage，需要等待这个消息处理完毕。但是，我们怎么能够知道这个消息处理完毕了？因为我们不可能等待DispatchMessage返回，而DispatchMessage失败则是因为我们并不知道应该往哪一个窗口分发消息。window manager给线程发送一个消息，仅此而已。</p>

<p>你可能会认为，我们可以等待知道下一个GetMessage or PeekMessage，这样我们可以确定这个消息解决了。但是，我们却不能保证下一个消息检索函数(GetMessage PeekMessage)，是来自我们之前的消息泵。比如，我们这个线程消息，启动了一个模态窗口，是的。当我们的消息检索函数告诉我们这个消息已经处理完毕了。但是，事实上那个模态窗口还在，因为他自己又创建了一个消息泵。“</p>

<p>这段虽然不长，但是却另我头大无比。GetMessage ，  DispatchMessage。这2个基本的函数，天天用，但是却对他们的行为知之甚少，算上第一次写HelloWorld 到现在，至少也有1年了，依然朦胧，感到十分惭愧。而这也就是这篇总结要做的。而这的确是一个庞大的工程，因为要了解这2个函数，需要把握windows的消息机制。而windwos 并没有给我们源代码参考，这里参考ReactOS的实现，虽然不是windows正统，但是，应该差不远，至少是和win2003的相似。开始步入正题。</p>

<p>我们首先需要了解的是，UI线程 和我们的普通的Worker线程之间的区别是什么。</p>

<p>msdn http://msdn.microsoft.com/en-us/library/ms644927提到：</p>

<p>”To avoid the overhead of creating a message queue for non–GUI threads, all threads are created initially without a message queue. The system creates a thread-specific message queue only when the thread makes its first call to one of the specific user functions; no GUI function calls result in the creation of a message queue.“</p>

<p>既然，系统创建每一个线程时都是普通的non–GUI thread，直到GDI， User函数调用，才为线程创建消息队列，那么我们就从这些函数调用开始。</p>

<p>windwos在开始时，和linux一样 图形这部分是在用户空间中的进程负责，后面为了减少进程之间的环境切换，而放入了内核中。那么在系统调用这层，我们就看到了有2种情况。一种调用是原来的”内核”的调用，而另一种是新加进来的原来在用户空间的调用，这部分被称为扩充系统调用，这部分代码被放在了可以动态安装的模块win32k.sys。与之对应，系统的调用表就有了2个，一个是只包括之前的”来自内核的系统调用“，另一个则在之前的基础上，增加了图形图像的系统调用。当我们的系统调用被发现是扩充系统调用时，也就是，原来的的表不能满足我们的要求。windwos会将会扩充系统调用表。并装载win32k.sys模块。那么，我们的普普通通的线程就开始变为GUI线程了。</p>

<p>激动人心的旅程就从这里开始了。</p>

<p>开源代码就是好，随意都能够贴出来。</p>

<pre><code>NTSTATUS
NTAPI
PsConvertToGuiThread(VOID)
{
    ULONG_PTR NewStack;
    PVOID OldStack;
    PETHREAD Thread = PsGetCurrentThread();
    PEPROCESS Process = PsGetCurrentProcess();
    NTSTATUS Status;
    PAGED_CODE();

    /* Validate the previous mode */
    if (KeGetPreviousMode() == KernelMode) return STATUS_INVALID_PARAMETER;

    /* If no win32k, crashes later */
    ASSERT(PspW32ProcessCallout != NULL);

    /* Make sure win32k is here */
    if (!PspW32ProcessCallout) return STATUS_ACCESS_DENIED;

    /* Make sure it's not already win32 */
    if (Thread-&gt;Tcb.ServiceTable != KeServiceDescriptorTable)
    {
        /* We're already a win32 thread */
        return STATUS_ALREADY_WIN32;
    }

    /* Check if we don't already have a kernel-mode stack */
    if (!Thread-&gt;Tcb.LargeStack)
    {
        /* We don't create one */
        NewStack = (ULONG_PTR)MmCreateKernelStack(TRUE, 0);
        if (!NewStack)
        {
            /* Panic in user-mode */
            NtCurrentTeb()-&gt;LastErrorValue = ERROR_NOT_ENOUGH_MEMORY;
            return STATUS_NO_MEMORY;
        }

        /* We're about to switch stacks. Enter a guarded region */
        KeEnterGuardedRegion();

        /* Switch stacks */
        OldStack = KeSwitchKernelStack((PVOID)NewStack,
                                       (PVOID)(NewStack - KERNEL_STACK_SIZE));

        /* Leave the guarded region */
        KeLeaveGuardedRegion();

        /* Delete the old stack */
        MmDeleteKernelStack(OldStack, FALSE);
    }

    /* This check is bizare. Check out win32k later */
    if (!Process-&gt;Win32Process)
    {
        /* Now tell win32k about us */
        Status = PspW32ProcessCallout(Process, TRUE);
        if (!NT_SUCCESS(Status)) return Status;
    }

    /* Set the new service table */
    Thread-&gt;Tcb.ServiceTable = KeServiceDescriptorTableShadow;
    ASSERT(Thread-&gt;Tcb.Win32Thread == 0);

    /* Tell Win32k about our thread */
    Status = PspW32ThreadCallout(Thread, PsW32ThreadCalloutInitialize);
    if (!NT_SUCCESS(Status))
    {
        /* Revert our table */
        Thread-&gt;Tcb.ServiceTable = KeServiceDescriptorTable;
    }

    /* Return status */
    return Status;
}
</code></pre>

<p>之前没有提到的是，这里判断了一下线程system stack的大小，因为GUI线程要比普通的线程增加了更多的嵌套调用，从而需要更多的system stack。MmCreateKernelStack就是分配空间的函数。这里只是分配了64K的大小，普通的thread system stack大小为12K。当然，按照惯例，这里64K的堆栈，只是提交了其中12K的大小。并设置好guard page。超过12K则产生异常然后再分配空间。一个进程，如果有一个线程是GUI线程，那么这个进程就是GUI 进程，那么，如果不是GUI进程，我们当然先得把进程转过来。PspW32ProcessCallout是一个函数指针，指向Win32kProcessCallback。这里就是干这个了，会初始化一系列的结构体，键盘格式，GDI 句柄表等等。我们这里略过这些细节。</p>

<p>我们看到，系统的ServiceTable换成了大的表。而PspW32ThreadCallout指向Win32kThreadCallback，这里就完成了把普通线程转换成GUI线程的过程。对于操作系统这么复杂的东东来说，要初始化的结构体真是茫茫的多。我们这里关注一点，在Win32kThreadCallback中，我们找到了创建消息队列的入口。Win32Thread->MessageQueue = MsqCreateMessageQueue(Thread);</p>

<p>系统有了消息队列，但是，并不能构成真正的win32应用程序。我们开发者，还需要在自己的窗口程序中构造一个简单的Message Dump，让我们看看这个GetMessage，到底做了什么。</p>

<p>GetMessage，最后会调用NtUserGetMessage。</p>

<pre><code>BOOL APIENTRY
NtUserGetMessage(PMSG pMsg,
                  HWND hWnd,
                  UINT MsgFilterMin,
                  UINT MsgFilterMax )
{
    MSG Msg;
    BOOL Ret;

    if ( (MsgFilterMin|MsgFilterMax) &amp; ~WM_MAXIMUM )
    {
        EngSetLastError(ERROR_INVALID_PARAMETER);
        return FALSE;
    }

    UserEnterExclusive();

    RtlZeroMemory(&amp;Msg, sizeof(MSG));

    Ret = co_IntGetPeekMessage(&amp;Msg, hWnd, MsgFilterMin, MsgFilterMax, PM_REMOVE, TRUE);

    UserLeave();

    if (Ret)
    {
        _SEH2_TRY
        {
            ProbeForWrite(pMsg, sizeof(MSG), 1);
            RtlCopyMemory(pMsg, &amp;Msg, sizeof(MSG));
        }
        _SEH2_EXCEPT(EXCEPTION_EXECUTE_HANDLER)
        {
            SetLastNtError(_SEH2_GetExceptionCode());
            Ret = FALSE;
        }
        _SEH2_END;
    }

    return Ret;
}
</code></pre>

<p>原谅我略过一些茫茫多的细节。</p>

<pre><code>BOOL FASTCALL
co_IntGetPeekMessage( PMSG pMsg,
                      HWND hWnd,
                      UINT MsgFilterMin,
                      UINT MsgFilterMax,
                      UINT RemoveMsg,
                      BOOL bGMSG )
{
    //.......
    do
    {
        Present = co_IntPeekMessage( pMsg,
                                     Window,
                                     MsgFilterMin,
                                     MsgFilterMax,
                                     RemoveMsg,
                                     bGMSG );
        if (Present)
        {
           /* GetMessage or PostMessage must never get messages that contain pointers */
           ASSERT(FindMsgMemory(pMsg-&gt;message) == NULL);

           if (pMsg-&gt;message != WM_PAINT &amp;&amp; pMsg-&gt;message != WM_QUIT)
           {
              pti-&gt;timeLast = pMsg-&gt;time;
              pti-&gt;ptLast   = pMsg-&gt;pt;
           }

           // The WH_GETMESSAGE hook enables an application to monitor messages about to
           // be returned by the GetMessage or PeekMessage function.

           co_HOOK_CallHooks( WH_GETMESSAGE, HC_ACTION, RemoveMsg &amp; PM_REMOVE, (LPARAM)pMsg);

           if ( bGMSG )
           {
              Present = (WM_QUIT != pMsg-&gt;message);
              break;
           }
        }

        if ( bGMSG )
        {
           if ( !co_IntWaitMessage(Window, MsgFilterMin, MsgFilterMax) )
           {
              Present = -1;
              break;
           }
        }
        else
        {
           if (!(RemoveMsg &amp; PM_NOYIELD))
           {
              IdlePing();
              // Yield this thread!
              UserLeave();
              ZwYieldExecution();
              UserEnterExclusive();
              // Fall through to exit.
              IdlePong();
           }
           break;
        }
    }
    while( bGMSG &amp;&amp; !Present );

    // Been spinning, time to swap vinyl...
    if (pti-&gt;pClientInfo-&gt;cSpins &gt;= 100)
    {
       // Clear the spin cycle to fix the mix.
       pti-&gt;pClientInfo-&gt;cSpins = 0;
       //if (!(pti-&gt;TIF_flags &amp; TIF_SPINNING)) FIXME need to swap vinyl..
    }
    return Present;
}
</code></pre>

<p>IntGetPeekMessage，就是一个循环，不断的调用co_IntPeekMessage 从消息队列中取出消息，如果没有消息，那么我们就调用co_IntWaitMessage等待消息，然后往复，除非我们遇到了WM_QUIT。</p>

<p>co_IntPeekMessage 看来是实现的关键,而他也是PeekMessage的关键部分。同样,略过那些繁琐的细节。当然，这并不是指那些不重要，而是实在是太多了。这个函数是整个消息机制的核心部分。需要慢慢来。</p>

<p>说了这么多，我们还不知道消息队列是啥模样了。</p>

<pre><code>typedef struct _USER_MESSAGE_QUEUE
{
  /* Reference counter, only access this variable with interlocked functions! */
  LONG References;

  /* Owner of the message queue */
  struct _ETHREAD *Thread;
  /* Queue of messages sent to the queue. */
  LIST_ENTRY SentMessagesListHead;                          //被“发送”的消息队列
  /* Queue of messages posted to the queue. */
  LIST_ENTRY PostedMessagesListHead;                        //被"Post"的消息队列
  /* Queue for hardware messages for the queue. */
  LIST_ENTRY HardwareMessagesListHead;                      //来自硬件的消息队列

  //.........

  /* messages that are currently dispatched by other threads */
  LIST_ENTRY DispatchingMessagesHead;                           //  已经发送而对方尚未处理的消息队列
  /* messages that are currently dispatched by this message queue, required for cleanup */
  LIST_ENTRY LocalDispatchingMessagesHead;                     // 本地正在分发的消息队列

  //........

} USER_MESSAGE_QUEUE, *PUSER_MESSAGE_QUEUE;
</code></pre>

<p>SentMessagesListHead 这个队列的东西是发送到我们这个消息队列的消息。 也就是，当其他地方调用SendMessage到我们这个消息队列时，那个消息会放在这个队列中。</p>

<p>PostedMessagesListHead 同理，是其他地方调用PostMessage，然后把他那个消息放在了这个队列中。</p>

<p>PostMessage这个函数比较容易实现，我们只需要挂在目标的PostedMessagesListHead队列中就可以了。但是SendMessage就要复杂很多了。</p>

<p>如果发送方和接收方是在一个线程中，那么SendMessage会直接调用本窗口的窗口过程函数来处理这个消息。</p>

<p>如果发送方和接收方不在一个线程中，那么发送方就必须要等待接收方的运行结果之后，才能继续执行。而这个，就形成了一个感觉上是同步的一个过程。感觉上这个似乎也不是很复杂。但也不是一个很简单的线程同步问题。</p>

<p>想一下这个问题，当GUI线程A向GUI线程B发送一个消息时，线程B处理A这个消息时，又需要向线程A发送一个消息。那么，这2个线程会死锁么？ 当然不会。要知道，windwos搞这一套为的就是构造一个完整的消息驱动机制，更抽象的讲，这个消息机制也算的上是一个线程通信机制。而这一套东东，最复杂的是在于，这些东东需要用户程序结合到一起，才能真正的运行起来。也就是说，我们的应用程序，必须符合windwos程序的规范，才能和windwos消息机制参与起来。而这个参与中最重要的东东就是我们之前提到的GetMessage，DispatchingMessagesHead 和 LocalDispatchingMessagesHead 则是实现这一套机制中非常重要的部分。</p>

<p>DispatchingMessagesHead  当我们自己SendMessage到其他地方时，我们的消息是需要等待对面的结果，那么这个需要等待的消息就被放置到这里。这里可能会对一些windwos菜鸟觉得困惑，困惑这个为什么能够形成一个队列呢？这里先把问题留下来。</p>

<p>让我们站在接受者的消息队列的角度来看，当有人给我们SendMessage了，我们需要在这里处理，也就是Message Dispatch，当我们搞出这个消息的返回值时，我们接受方，还必须等待对面的人把我们的这个消息的返回值拿走，这个消息才算是搞定了。这里由于可能是不同线程，甚至是不同进程之间数据传递。所以这些东西必须要考虑在内，而这些消息放在哪里呢？LocalDispatchingMessagesHead 就跳出来解决这个问题。</p>

<p>总的说一下，当我们SendMessage一个消息时，会挂在接收方的SentMessagesListHead队列中，并挂在发送方的DispatchingMessagesHead。</p>

<p>接受方先查看SentMessagesListHead 是否有消息，有的话，则从SendMessageListHead中删除掉，并添加到LocalDispatchingMessagesHead队列中，等我们把这个消息处理完毕，从LocalDispatchingMessagesHead将这个消息删除。</p>

<p>我们首先关注这4个队列。那个硬件的队列主要是鼠标和键盘的东东。</p>

<p>第一次看这个可能有点晕，不急。有一个笼统的概念之后，我们在来看细节。这部分还不是非常复杂。</p>

<pre><code>/*
 * Internal version of PeekMessage() doing all the work
 */
BOOL FASTCALL
co_IntPeekMessage( PMSG Msg,
                   PWND Window,
                   UINT MsgFilterMin,
                   UINT MsgFilterMax,
                   UINT RemoveMsg,
                   BOOL bGMSG )
{
    //...
    do
    {
        //..
        /* Dispatch sent messages here. */
        while ( co_MsqDispatchOneSentMessage(ThreadQueue) )
        {
           //...
        }

        //...

        /* Now check for normal messages. */
        if ((ProcessMask &amp; QS_POSTMESSAGE) &amp;&amp;
            MsqPeekMessage( ThreadQueue,
                            RemoveMessages,
                            Window,
                            MsgFilterMin,
                            MsgFilterMax,
                            ProcessMask,
                            Msg ))
        {
               return TRUE;
        }

        /* Now look for a quit message. */
        if (ThreadQueue-&gt;QuitPosted)
        {
            /* According to the PSDK, WM_QUIT messages are always returned, regardless
               of the filter specified */
            Msg-&gt;hwnd = NULL;
            Msg-&gt;message = WM_QUIT;
            Msg-&gt;wParam = ThreadQueue-&gt;QuitExitCode;
            Msg-&gt;lParam = 0;
            if (RemoveMessages)
            {
                ThreadQueue-&gt;QuitPosted = FALSE;
                ClearMsgBitsMask(ThreadQueue, QS_POSTMESSAGE);
                pti-&gt;pcti-&gt;fsWakeBits &amp;= ~QS_ALLPOSTMESSAGE;
                pti-&gt;pcti-&gt;fsChangeBits &amp;= ~QS_ALLPOSTMESSAGE;
            }
            return TRUE;
        }

        /* Check for hardware events. */
        if ((ProcessMask &amp; QS_MOUSE) &amp;&amp;
            co_MsqPeekMouseMove( ThreadQueue,
                                 RemoveMessages,
                                 Window,
                                 MsgFilterMin,
                                 MsgFilterMax,
                                 Msg ))
        {
            return TRUE;
        }

        if ((ProcessMask &amp; QS_INPUT) &amp;&amp;
            co_MsqPeekHardwareMessage( ThreadQueue,
                                       RemoveMessages,
                                       Window,
                                       MsgFilterMin,
                                       MsgFilterMax,
                                       ProcessMask,
                                       Msg))
        {
            return TRUE;
        }

        /* Check for sent messages again. */
        while ( co_MsqDispatchOneSentMessage(ThreadQueue) )
        {
           if (HIWORD(RemoveMsg) &amp;&amp; !bGMSG) Hit = TRUE;
        }
        if (Hit) return FALSE;

        /* Check for paint messages. */
        if ((ProcessMask &amp; QS_PAINT) &amp;&amp;
            pti-&gt;cPaintsReady &amp;&amp;
            IntGetPaintMessage( Window,
                                MsgFilterMin,
                                MsgFilterMax,
                                pti,
                                Msg,
                                RemoveMessages))
        {
            return TRUE;
        }

       /* This is correct, check for the current threads timers waiting to be
          posted to this threads message queue. If any we loop again.
        */
        if ((ProcessMask &amp; QS_TIMER) &amp;&amp;
            PostTimerMessages(Window))
        {
            continue;
        }

        return FALSE;
    }
    while (TRUE);

    return TRUE;
}
</code></pre>

<p>co_MsqDispatchOneSentMessage 这里做的就是从SendMessageListHead 中取出一个别人SendMessage到我们这里的一个消息。 当我们把这些别人SendMessage给我们的消息处理完，就跳出那个循环，MsqPeekMessage 则去搞定别人PostMessage给我们的消息，最后再次检查一次co_MsqDispatchOneSentMessage，有没有人给我们发送了SendMessage消息，因为这之间的间隔是有可能有新的SendMessage消息。然后是IntGetPaintMessage 和PostTimerMessages这个名字就很容易理解了。而且，这里我们也看出了消息的优先级，为了提高Paint的效率，Paint是统一处理的。而且我们也看到了Timer消息，事实上我们看出他的优先级低于Paint，这样，我们就可以在timer中绘制函数，因为，我们每一次处理timer之前，我们能够保证我们的Paint消息已经被处理了。而且，我们也看出timer的确不准，在他前面有太多的东西要做了。</p>

<p>我们还需要了解下，我们的消息结构。是的，这个Post消息是要挂在队列中的。</p>

<pre><code>typedef struct _USER_MESSAGE
{
  LIST_ENTRY ListEntry;
  MSG Msg;
  DWORD QS_Flags;
} USER_MESSAGE, *PUSER_MESSAGE;
</code></pre>

<p>Send的消息这里就要麻烦很多了。</p>

<pre><code>typedef struct _USER_SENT_MESSAGE
{
  LIST_ENTRY ListEntry;                            //接受方的队列
  MSG Msg;
  DWORD QS_Flags;  // Original QS bits used to create this message.
  PKEVENT CompletionEvent;                    //这个用来做线程的唤醒操作
  LRESULT* Result;
  LRESULT lResult;
  struct _USER_MESSAGE_QUEUE* SenderQueue;
  struct _USER_MESSAGE_QUEUE* CallBackSenderQueue;
  SENDASYNCPROC CompletionCallback;
  ULONG_PTR CompletionCallbackContext;
  /* entry in the dispatching list of the sender's message queue */
  LIST_ENTRY DispatchingListEntry;                //发送方的DispatchingMessageList
  INT HookMessage;
  BOOL HasPackedLParam;
} USER_SENT_MESSAGE, *PUSER_SENT_MESSAGE;
</code></pre>

<p>这个家伙，才是真正挂在发送队列中的数据结构，我们的MSG只是其中的一个数据成员。这里，就和我们之前提到的，这个消息，是在2个队列中存在，一边在发送方的DispatchingMessageList，表示这个消息正在分发，一边在接受方的SentMessagesListHead，表示这个消息被发送过来。等待处理。</p>

<p>让我们一看co_MsqDispatchOneSentMessage的究竟。</p>

<pre><code>BOOLEAN FASTCALL
co_MsqDispatchOneSentMessage(PUSER_MESSAGE_QUEUE MessageQueue)
{
   PUSER_SENT_MESSAGE SaveMsg, Message;
   PLIST_ENTRY Entry;
   LRESULT Result;
   PTHREADINFO pti;

   if (IsListEmpty(&amp;MessageQueue-&gt;SentMessagesListHead))
   {
      return(FALSE);
   }

   /* remove it from the list of pending messages */
   Entry = RemoveHeadList(&amp;MessageQueue-&gt;SentMessagesListHead);
   Message = CONTAINING_RECORD(Entry, USER_SENT_MESSAGE, ListEntry);

   pti = MessageQueue-&gt;Thread-&gt;Tcb.Win32Thread;

   SaveMsg = pti-&gt;pusmCurrent;
   pti-&gt;pusmCurrent = Message;

   // Processing a message sent to it from another thread.
   if ( ( Message-&gt;SenderQueue &amp;&amp; MessageQueue != Message-&gt;SenderQueue) ||
        ( Message-&gt;CallBackSenderQueue &amp;&amp; MessageQueue != Message-&gt;CallBackSenderQueue ))
   {  // most likely, but, to be sure.
      pti-&gt;pcti-&gt;CTI_flags |= CTI_INSENDMESSAGE; // Let the user know...
   }

   /* insert it to the list of messages that are currently dispatched by this
      message queue */
   InsertTailList(&amp;MessageQueue-&gt;LocalDispatchingMessagesHead,
                  &amp;Message-&gt;ListEntry);

   ClearMsgBitsMask(MessageQueue, Message-&gt;QS_Flags);

   if (Message-&gt;HookMessage == MSQ_ISHOOK)
   {  // Direct Hook Call processor
      Result = co_CallHook( Message-&gt;Msg.message,     // HookId
                           (INT)(INT_PTR)Message-&gt;Msg.hwnd, // Code
                            Message-&gt;Msg.wParam,
                            Message-&gt;Msg.lParam);
   }
   else if (Message-&gt;HookMessage == MSQ_ISEVENT)
   {  // Direct Event Call processor
      Result = co_EVENT_CallEvents( Message-&gt;Msg.message,
                                    Message-&gt;Msg.hwnd,
                                    Message-&gt;Msg.wParam,
                                    Message-&gt;Msg.lParam);
   }
   else
   {  /* Call the window procedure. */
      Result = co_IntSendMessage( Message-&gt;Msg.hwnd,
                                  Message-&gt;Msg.message,
                                  Message-&gt;Msg.wParam,
                                  Message-&gt;Msg.lParam);
   }

   /* remove the message from the local dispatching list, because it doesn't need
      to be cleaned up on thread termination anymore */
   RemoveEntryList(&amp;Message-&gt;ListEntry);

   /* remove the message from the dispatching list if needed, so lock the sender's message queue */
   if (!(Message-&gt;HookMessage &amp; MSQ_SENTNOWAIT))
   {
      if (Message-&gt;DispatchingListEntry.Flink != NULL)
      {
         /* only remove it from the dispatching list if not already removed by a timeout */
         RemoveEntryList(&amp;Message-&gt;DispatchingListEntry);
      }
   }
   /* still keep the sender's message queue locked, so the sender can't exit the
      MsqSendMessage() function (if timed out) */

   if (Message-&gt;QS_Flags &amp; QS_SMRESULT)
   {
      Result = Message-&gt;lResult;
   }

   /* Let the sender know the result. */
   if (Message-&gt;Result != NULL)
   {
      *Message-&gt;Result = Result;
   }

   if (Message-&gt;HasPackedLParam == TRUE)
   {
      if (Message-&gt;Msg.lParam)
         ExFreePool((PVOID)Message-&gt;Msg.lParam);
   }

   /* Notify the sender. */
   if (Message-&gt;CompletionEvent != NULL)
   {
      KeSetEvent(Message-&gt;CompletionEvent, IO_NO_INCREMENT, FALSE);
   }

   /* Call the callback if the message was sent with SendMessageCallback */
   if (Message-&gt;CompletionCallback != NULL)
   {
      co_IntCallSentMessageCallback(Message-&gt;CompletionCallback,
                                    Message-&gt;Msg.hwnd,
                                    Message-&gt;Msg.message,
                                    Message-&gt;CompletionCallbackContext,
                                    Result);
   }

   /* Only if it is not a no wait message */
   if (!(Message-&gt;HookMessage &amp; MSQ_SENTNOWAIT))
   {
      IntDereferenceMessageQueue(Message-&gt;SenderQueue);
      IntDereferenceMessageQueue(MessageQueue);
   }

   /* free the message */
   ExFreePoolWithTag(Message, TAG_USRMSG);

   /* do not hangup on the user if this is reentering */
   if (!SaveMsg) pti-&gt;pcti-&gt;CTI_flags &amp;= ~CTI_INSENDMESSAGE;
   pti-&gt;pusmCurrent = SaveMsg;

   return(TRUE);
}
</code></pre>

<p>我们首先从SentMessagesListHead把消息移动到LocalDispatchingMessagesHead，让我们略掉那些细节的标志位和hook的部分。co_IntSendMessage，则把这个消息发送出去，然后把结果给我们，然后我们把消息从接收方的LocalDispatchingMessagesHead，删掉。如果发送方还在等我们的消息，我们就把他从发送方的DispatchingMessagesHead中删掉这条消息，（因为有些消息，是有时间限制的，可能已经早就被从DispatchingMessagesHead删掉了）。然后把返回结果保存起来。当然，有些消息还是有附件的，一些资源需要释放。这里是那些消息就不在这里赘述了，而且我们也不关心这些。然后，我们通过Message->CompletionEvent来通知发送方，该醒过来了。最后，我们看到，如果这个消息有回调函数，这里并没有直接调用回调函数，而是又通过了消息机制发送了一个消息给自己（在自己的Post队列中）。有了这个，的确很容易去理解MSDN的相关意思了。有时候，真的。MS的文档为什么那么全，因为他不给我们看源代码，有源代码还需要那么多的详细文档么？而且，那些文档真的不能彻底说清楚。</p>

<p>转了这么远，问题又被迭代到co_IntSendMessage 上了。co_IntSendMessage 其实是co_IntSendMessageTimeout 的一个特殊调用。</p>

<pre><code>LRESULT FASTCALL
co_IntSendMessageTimeout( HWND hWnd,
                          UINT Msg,
                          WPARAM wParam,
                          LPARAM lParam,
                          UINT uFlags,
                          UINT uTimeout,
                          ULONG_PTR *uResult )
{
    PWND DesktopWindow;
    HWND *Children;
    HWND *Child;

    if (HWND_BROADCAST != hWnd)
    {
        return co_IntSendMessageTimeoutSingle(hWnd, Msg, wParam, lParam, uFlags, uTimeout, uResult);
    }

    DesktopWindow = UserGetWindowObject(IntGetDesktopWindow());
    if (NULL == DesktopWindow)
    {
        EngSetLastError(ERROR_INTERNAL_ERROR);
        return 0;
    }

    /* Send message to the desktop window too! */
    co_IntSendMessageTimeoutSingle(DesktopWindow-&gt;head.h, Msg, wParam, lParam, uFlags, uTimeout, uResult);

    Children = IntWinListChildren(DesktopWindow);
    if (NULL == Children)
    {
        return 0;
    }

    for (Child = Children; NULL != *Child; Child++)
    {
        co_IntSendMessageTimeoutSingle(*Child, Msg, wParam, lParam, uFlags, uTimeout, uResult);
    }

    ExFreePool(Children);

    return (LRESULT) TRUE;
}
</code></pre>

<p>我们不考虑广播的情况，看简单的给单个窗口发送消息的co_IntSendMessageTimeoutSingle</p>

<pre><code>static LRESULT FASTCALL
co_IntSendMessageTimeoutSingle( HWND hWnd,
                                UINT Msg,
                                WPARAM wParam,
                                LPARAM lParam,
                                UINT uFlags,
                                UINT uTimeout,
                                ULONG_PTR *uResult )
{
    NTSTATUS Status;
    PWND Window = NULL;
    PMSGMEMORY MsgMemoryEntry;
    INT lParamBufferSize;
    LPARAM lParamPacked;
    PTHREADINFO Win32Thread;
    ULONG_PTR Result = 0;
    DECLARE_RETURN(LRESULT);
    USER_REFERENCE_ENTRY Ref;

    if (!(Window = UserGetWindowObject(hWnd)))
    {
        RETURN( FALSE);
    }

    UserRefObjectCo(Window, &amp;Ref);

    Win32Thread = PsGetCurrentThreadWin32Thread();

    IntCallWndProc( Window, hWnd, Msg, wParam, lParam);

    if ( NULL != Win32Thread &amp;&amp;
         Window-&gt;head.pti-&gt;MessageQueue == Win32Thread-&gt;MessageQueue)
    {
        //本线程的消息，我们直接调用用户的窗口回调函数，终于要结束了。
        Result = (ULONG_PTR)co_IntCallWindowProc( Window-&gt;lpfnWndProc,
                                                  !Window-&gt;Unicode,
                                                  hWnd,
                                                  Msg,
                                                  wParam,
                                                  lParamPacked,
                                                  lParamBufferSize );
        if(uResult)
        {
            *uResult = Result;
        }

        ObDereferenceObject(Win32Thread-&gt;pEThread);

        IntCallWndProcRet( Window, hWnd, Msg, wParam, lParam, (LRESULT *)uResult);

        if (! NT_SUCCESS(UnpackParam(lParamPacked, Msg, wParam, lParam, FALSE)))
        {
            DPRINT1("Failed to unpack message parameters\n");
            RETURN( TRUE);
        }

        RETURN( TRUE);
    }

    //不是本线程，我们只能去转发这个消息了。

    do
    {
        Status = co_MsqSendMessage( Window-&gt;head.pti-&gt;MessageQueue,
                                    hWnd,
                                    Msg,
                                    wParam,
                                    lParam,
                                    uTimeout,
                                    (uFlags &amp; SMTO_BLOCK),
                                    MSQ_NORMAL,
                                    uResult );
    }
    while ((STATUS_TIMEOUT == Status) &amp;&amp;
           (uFlags &amp; SMTO_NOTIMEOUTIFNOTHUNG) &amp;&amp;
           !MsqIsHung(Window-&gt;head.pti-&gt;MessageQueue));

    IntCallWndProcRet( Window, hWnd, Msg, wParam, lParam, (LRESULT *)uResult);

    if (STATUS_TIMEOUT == Status)
    {
        /*
MSDN says:
    Microsoft Windows 2000: If GetLastError returns zero, then the function
    timed out.
    XP+ : If the function fails or times out, the return value is zero.
    To get extended error information, call GetLastError. If GetLastError
    returns ERROR_TIMEOUT, then the function timed out.
*/
        EngSetLastError(ERROR_TIMEOUT);
        RETURN( FALSE);
    }
    else if (! NT_SUCCESS(Status))
    {
        SetLastNtError(Status);
        RETURN( FALSE);
    }

    RETURN( TRUE);

CLEANUP:
    if (Window) UserDerefObjectCo(Window);
    END_CLEANUP;
}
</code></pre>

<p>这里我们终于看到结果了。当然，这里又给我们带出一个问题”系统是如何调用我们写的函数呢？是在什么时候调用？是通过什么方式？”这同样是，特别是第一次写windwos程序的菜鸟们遇到的第一个问题。这个问题说清楚还是挺麻烦的。这部分这里先留下。</p>

<p>让我们把大脑堆栈弹到开始。</p>

<p>还是这个问题”系统是如何调用我们写的函数呢？是在什么时候调用？是通过什么方式？”现在我们还不能回答所有问题，但是却可以回答”系统什么时候调用我们的窗口过程函数”。</p>

<p>我们调用系统的代码，或是说是调用系统服务，API等什么的，是通过中断机制完成的。并通过查找系统调用表来找到相对应的系统函数。也就是，我们可以随时随地利用中断机制去执行系统代码（当然是在限制下）。那么，系统可以随时随地的去执行我们用户空间的代码么？有点难，我们不去思考那么复杂的，因为还有一些其他的机制做这些类似的工作。我们只是去思考其中的一种，如何调用我们的窗口过程函数。</p>

<p>很容易想到，随时随地执行用户的代码很难。因为没有硬件的支持去让我们完成类似中断的机制。那系统只能在一些特定的地方才能有机会去执行我们的窗口过程函数。显然，GetMessage就是这个执行用户窗口过程函数的地方。而当用户程序在处理一个消息时，系统是没有办法有任何作为的。只能等待用户下一次调用GetMessage类似的函数，才能重新获得代码的控制。我们在co_IntPeekMessage中看出些端倪。如果消息队列中，没有任何消息，那么GetMessage并不会退出，也就是不将执行权给用户的代码，而是进入等待状态。如果这时来的一些SendMessage的消息，线程会唤醒并执行这些代码。除非有一个Post或是其他消息，才会从GetMessage返回给用户空间。</p>

<p>换句话就是，如果我们的Sendmessage是发给不同的线程，只能在GetMessage这个函数内部执行。如果那个接收方的线程阻塞了，那么我们的SendMessage就不会返回，因为他并没有执行GetMessage。</p>

<p>在去思考另一个问题，当我们Sendmessage到另一个线程，而另一个线程并没有执行我们的GetMessage，在执行他的代码，而我们的线程看起来显然是被挂起等待了，是么？并不是，因为他还是可以接受其他线程发送过来的消息。这显然是处理在处理我们之前讨论过的一种情况。的确很有意思。因为从windwos的角度看，需要实现这种强壮的消息机制。那么这是一个什么过程呢？清楚一点。其实就是需要一种机制，也就是在等待对方线程处理完毕之前，可以处理别人发给我们的消息。哈哈。WaitForMultipleObjects等待2个event一个是要等待处理完毕的消息，一个是要等待sendmessage过来的新消息。当醒来时判断是什么让我们清醒过来，如果对面的线程不给力，我们只能继续循环等待。而这个也就是sendmessage的过程。</p>

<pre><code>NTSTATUS FASTCALL
co_MsqSendMessage(PUSER_MESSAGE_QUEUE MessageQueue,
                  HWND Wnd, UINT Msg, WPARAM wParam, LPARAM lParam,
                  UINT uTimeout, BOOL Block, INT HookMessage,
                  ULONG_PTR *uResult)
{
   PTHREADINFO pti;
   PUSER_SENT_MESSAGE Message;
   KEVENT CompletionEvent;
   NTSTATUS WaitStatus;
   PUSER_MESSAGE_QUEUE ThreadQueue;
   LARGE_INTEGER Timeout;
   PLIST_ENTRY Entry;
   LRESULT Result = 0;   //// Result could be trashed. ////

   if(!(Message = ExAllocatePoolWithTag(PagedPool, sizeof(USER_SENT_MESSAGE), TAG_USRMSG)))
   {
      DPRINT1("MsqSendMessage(): Not enough memory to allocate a message");
      return STATUS_INSUFFICIENT_RESOURCES;
   }

   KeInitializeEvent(&amp;CompletionEvent, NotificationEvent, FALSE);

   pti = PsGetCurrentThreadWin32Thread();
   ThreadQueue = pti-&gt;MessageQueue;
   ASSERT(ThreadQueue != MessageQueue);

   Timeout.QuadPart = (LONGLONG) uTimeout * (LONGLONG) -10000;

   /* FIXME - increase reference counter of sender's message queue here */

   Message-&gt;Msg.hwnd = Wnd;
   Message-&gt;Msg.message = Msg;
   Message-&gt;Msg.wParam = wParam;
   Message-&gt;Msg.lParam = lParam;
   Message-&gt;CompletionEvent = &amp;CompletionEvent;
   Message-&gt;Result = &amp;Result;
   Message-&gt;lResult = 0;
   Message-&gt;QS_Flags = 0;
   Message-&gt;SenderQueue = ThreadQueue;
   Message-&gt;CallBackSenderQueue = NULL;
   IntReferenceMessageQueue(ThreadQueue);
   Message-&gt;CompletionCallback = NULL;
   Message-&gt;CompletionCallbackContext = 0;
   Message-&gt;HookMessage = HookMessage;
   Message-&gt;HasPackedLParam = FALSE;

   IntReferenceMessageQueue(MessageQueue);

   /* add it to the list of pending messages */
   InsertTailList(&amp;ThreadQueue-&gt;DispatchingMessagesHead, &amp;Message-&gt;DispatchingListEntry);

   /* queue it in the destination's message queue */
   InsertTailList(&amp;MessageQueue-&gt;SentMessagesListHead, &amp;Message-&gt;ListEntry);

   Message-&gt;QS_Flags = QS_SENDMESSAGE;
   MsqWakeQueue(MessageQueue, QS_SENDMESSAGE, TRUE);

   /* we can't access the Message anymore since it could have already been deleted! */

   if(Block)
   {
      //我们绝大部分都是不阻塞的。
   }
   else
   {
      PVOID WaitObjects[2];

      WaitObjects[0] = &amp;CompletionEvent;
      WaitObjects[1] = ThreadQueue-&gt;NewMessages;
      do
      {
         UserLeaveCo();

         WaitStatus = KeWaitForMultipleObjects(2, WaitObjects, WaitAny, UserRequest,
                                               UserMode, FALSE, (uTimeout ? &amp;Timeout : NULL), NULL);

         UserEnterCo();

         if(WaitStatus == STATUS_TIMEOUT)
         {
            //...
         }
         while (co_MsqDispatchOneSentMessage(ThreadQueue))
            ;
      }
      while (NT_SUCCESS(WaitStatus) &amp;&amp; STATUS_WAIT_0 != WaitStatus);
   }

   if(WaitStatus != STATUS_TIMEOUT)
      *uResult = (STATUS_WAIT_0 == WaitStatus ? Result : -1);

   return WaitStatus;
}
</code></pre>

<p>GetMessage返回了，一般是跑2个函数。</p>

<p>TranslateMessage(&amp;msg);
DispatchMessage(&amp;msg);</p>

<p>这里我们不讨论TranslateMessage，这个主要是辅助一些硬件消息相关。</p>

<p>DispatchMessage的事情，就是做这个调用相对用的窗口过程部分。这部分主要是从系统调用我们的代码，目前对这个还没有什么兴趣。</p>

<p>类似的还有模态窗口，产生模态窗口的窗口，会阻塞一些消息，但是却不是阻塞所有的消息，别的线程依然可以给发SendMessage。为什么呢？他们之间会有联系么？</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/02/27/computer2/">胡言乱语计算机二</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-02-27T23:08:00+08:00" pubdate data-updated="true">Feb 27<span>th</span>, 2011</time>
        

        
      | <a href="/blog/2011/02/27/computer2/#comments">Comments</a>
        

      </p>
    
  </header>


  <div class="entry-content"><p>中断和异常处理是OS中非常重要的组成部分，当然windows也不例外，他们是我们理解OS一些概念、机制的基础。</p>

<p>中断和异常简单的来说，就是在程序正常执行流程中，突发一个事件，导致程序的执行流程转向另外的执行流程中。而我们绝大多数编写的程序都是顺序执行的，我们的确体会不到这样的机制能够给我们带来多少好处。但是这个在OS的设计中，确实深入到各个方面，以至于没有中断异常处理，现代OS根本无法构建。为了简单理解，我们可以看看这个例子。</p>

<p>比如我们准备带我们的宠物狗狗出去散步，但是由于狗狗非常淘气，经常单独行动（这里，我们是无法预知狗狗会在什么时候跑掉的），在没有任何其他道具的帮助下，我们只能每隔一段时间去看看狗狗是否跟着我们。那么用code来模仿这个行为，那么就是这个样子。</p>

<pre><code>while(living) //人的行为简单说其实就是不断的重复重复...
{
    //do something
    ...
    if(!VerifyDog())//看看狗狗还跟的没有
    {
        //狗丢了....    
    }
    ...    
}
</code></pre>

<p>如果我们这个while循环中，没有其他事情，仅仅是和狗狗在一起，那么狗狗不会丢，但是如果我们突然遇到一个美女，驻足观赏了一会之后…狗狗不见了。</p>

<p>是的，我们通过轮询这种方式，不可能保证狗狗一定会在我们身边。那么如何才能保证狗狗一定在我们身边呢？无论我们走到哪里都会紧紧跟着呢？生活常识告诉我们，只需要给狗狗戴上链子，这样狗狗就会“听话”的跟在我们左右。那么我们就可以通过这样的code来展示我们的行为。</p>

<pre><code>while(living)
{
    leash(FuncProc); 
    while(bOutSide)
    {
       //doSomeThing 
    }
    UnLeash();    
}

FuncProc()
{
    狗狗想跑,抓紧链子。：）
}
</code></pre>

<p>好了，在我们带狗狗出去玩之前，我们给狗狗栓了链子，那么我们在外出的时候，就可以随行所欲的“看美女了”。一旦狗狗有不轨行为，我们只是需要下意识的抓紧便能保证狗狗不会跑丢。而这，要比隔一段时间查看狗狗在不在要简单多了，我们可以完全从这个事情上解脱出来。做更重要的事情。而这一切，其实就是默默跑了一个异常处理的过程。</p>

<p>我们通过leash(FuncProc); 注册了一个callback函数
我们可以做我们想做的事情，而不在我们的while循环中体现任何有关狗狗的信息。
当狗狗有不轨行为时，链子第一时间通知我们狗狗的行为，然后我们能够在第一时间制止狗狗。
然后我们继续while中的事情。
当然，回家了要把狗狗放出来（大部分的狗狗都不喜欢狗链子….）。
从某种角度上来看，OS相当于人，而我们写的一些应用层的程序则相当于宠物狗狗。而异常处理，就是这条链子。对操作系统来说，他希望找到一条能够应对所有狗狗的超级链子。而在这么多狗狗中，总有那些不听话的，希望能够摆脱这条链子的狗狗。而这条链子也在这2端的发展下，变得越来越强壮。</p>

<p>这篇文章的角度就是站在OS的角度，希望找到这条能够应对各种狗狗（主要是不听话的狗狗）的链子。也就是初步学习windows 的SEH的整体设计和思路（这个帽子的确很大）。下一篇则站在狗狗的角度来学习我们如何能够摆脱这条链子（这个帽子也挺大的），也就是SEH的相关安全机制。当然这篇是理解后面的基础。</p>

<p>当然，OS本身的实现和人狗链子的关系也是微妙的。现代操作系统的整个设计是分层的。有些时候是人是狗已经不再重要了。就像真实世界的我们，我们无法从那些枷锁中挣脱，真的。我们有时候真不知道我们是人？是狗？</p>

<p>闲话扯得太多了。为了更清楚的了解异常，我们需要进一步了解我们的计算机。类似的这种程序控制流的变化，还有中断(interrupt)，陷阱(trap)，错误(fault)，终止（abort）而中断，我们通常又分为软中断，和硬中断（这个又通常省略硬字）。是的，我相信对于绝大多数的和我一个水平的菜鸟来说，这些概念都是可以令人抓狂的。而造成这样的原因主要是在于计算机的发展是在是太快速了，所以，有些概念在这个过程中得到了扩展，而这些概念又和计算机体系结构密切相关，所以我们经常看到甚至是一些权威书籍之间有概念的冲突，是的。这个当然不是人家的错误，只是处在了不同的时空，而这也就是语言的悲剧。他永远不可能给我们准确的答案，除非数学。所以这里我们需要先搞清楚这些概念。把那些恼人的语言上的细枝末节过滤掉之后，整个东东也不复杂了。当然整个学习都在我们最“熟悉”的x86下，其他平台也不不难掌握了。</p>

<p>为了减少中英文的差异，在一些概念描述上，这里就不再一次引入另一门语言，虽然他是伟大的语言。为了能够较为清晰的了解他们之间的区别。我们不得不扯一些硬件相关的知识，事实上，也许这些“旁敲侧击”让你回想到了学校的那些认为不重要的课程《机组》《模电》《计算机体系结构》《微机原理接口》等。</p>

<p>在8086下，原谅我再次重复，有2种这样的机制。interrupt、exception。interrupt分为可屏蔽中断和不可屏蔽中断。exception分为 fault、trap、abort。概念有点多，慢慢来。</p>

<p>经过上一篇的胡扯，我们知道了CPU眼中，把这些硬件当成逻辑存储器，最后和存储器构成一个地址空间。但是有些笼统，这里稍微再了解一点。和CPU通过总线相连的芯片除了各种存储器外，还有3种芯片</p>

<ul>
<li>各种接口卡（显卡，网卡）上的接口芯片，它们控制接口卡</li>
<li>主板上的接口芯片，CPU通过它们对一些外设访问</li>
<li>其他芯片，存储相关的系统信息或对输入输出处理</li>
</ul>


<p>而这些芯片都有一组可以由CPU读写的寄存器。这些寄存器有2点相同。</p>

<ul>
<li>和CPU总线相连。</li>
<li>CPU对它们进行读写是通过控制些向他们所在的芯片发出端口读写命令</li>
</ul>


<p>所以，在CPU看来，这些外部的寄存器相当于端口，并对他们一起编址，从而又搞了一个端口地址空间，或是叫做IO端口空间。这里再扯的远一点，事实上，在x86下，我们现在知道有2个地址空间，一个是存储器的地址空间还有一个是IO地址空间，为什么不把IO地址空间也映射到存储器地址空间中呢？这样我们就可以再弄一些逻辑存储器了。是的这样设计的确简单，但是却浪费了一些CPU的地址空间，所以当时intel考虑到为了不浪费而又搞了一个IO地址空间，所以我们访问这些端口的时候，也就必须通过另外的指令来做。我们把这种IO编址称为独立编址。x86一共有64K个8bit的IO端口。事实上还有另一种思路和我们之前的想法一致，将这些IO的空间跑到了存储器地址空间，而这个又叫做统一编址。也就是说，这些IO寄存器与存储器单元一样看待。这样的设计在ARM中则比较常见。呵呵，有点乱，让我们看个例子。</p>

<p>那就用我们最熟悉的键盘来说。当我们在键盘上操作时，CPU是如何知道的呢？</p>

<p>键盘中有专门的芯片用于监视键盘上每一个键的状态，当我们按下一个键时，接通电路，这个芯片就会产生一个成为扫描码的东东，来表示键的位置，当键弹起的时候，同样产生一个扫描码。扫描码就保存在了键盘接口芯片的寄存器中（CPU来看这就是一个端口）。那么当键盘的输入到到端口时，我们这篇文章的主角终于来了。芯片向CPU发出中断信息。到这里，键盘的事情OK了。</p>

<p>那么芯片是如何给CPU发送中断呢？我们可以通过线将CPU和芯片连接起来，但是这样会遇到一个无法回避的问题，可以和CPU连接的线是有限的，但是CPU外部的这些设备确是非常多的，所以必须管理这些设备，让其中一些设备共享一条线。而这也就是中断控制器的作用之一，所以，真实的情况是类似如下的。</p>

<p><img src="/images/computer2.png" alt="alt text" /></p>

<p>inter x86通过2片中断控制器8259A来响应外部中断源（就是指产生中断的设备，比如键盘）。和中断控制器相连的每条线被称为中断线。我们看出如果想发送中断给CPU，那么必须得获得这条线的控制权。那么我们申请中断线的这个动作，叫做IRQ（Interrupt ReQuirement）。当然“申请中断线”这也有一个更加专业的叫法申请IRQ或是申请中断号。</p>

<p>而这个8259A做的事情就是</p>

<ul>
<li>监视中断线，检查产生的IRQ信号</li>
<li><p>如果中断线上产生了一个IRQ信号</p>

<p>  把IRQ信号转换成对应的中断向量
  这个向量存放在中断控制器的一个IO端口，CPU从而可以通过数据总线访问向量
  这个信号则发送到CPU的INTR引脚，也即是触发一个中断
  等待CPU确认中断之后，写入PIC(可编程中断控制器)的IO端口，并清INTR</p></li>
</ul>


<p>但是事实上还没有完，我们知道CPU在一个时刻只能处理一个事情。我们有那么多的外围设备，当他们都要CPU时间时，这里就有一个先后问题了。也就是需要对这些中断分级别。而且在有些特殊的中断下，是不可以被其他中断打断的。呵呵，这里就引入了可屏蔽中断和不可屏蔽中断。那么我们就可以有选择的处理一些中断，而放弃另一些中断在一些极端情况下。而且有些中断处理过程中是不可以再处理中断的。可屏蔽中断IRQ信号通常是通过CPU的INTR引脚发给CPU的。而不可屏蔽中断信号通常是通过NMI引脚发给CPU。呵呵，这就是可屏蔽中断和不可屏蔽中断区别之一。</p>

<p>那么我们再来搞定异常。</p>

<p>为了能够稍微再了解一点，我们需要知道一些CPU内部是如何执行一条指令的。原谅我这里就不赘述了。只是搞一个例子。</p>

<p>当CPU执行汇编指令IDIV。首先会检查源操作数（除数）是否为0，如果为0，则CPU在执行这条指令中，就会产生一个除零异常（在CPU眼里，汇编也成高级语言了）。通过中断的例子，我们看出，中断是CPU外部告诉CPU的执行流程需要转变。那么异常和中断最大的不同就是异常是CPU自己本身执行时发现的。中断的来源通常是外部设备，异常的来源则有3种。</p>

<ul>
<li>程序错误，当CPU在执行程序指令时遇到操作数错误或是指令非法。前者的例子就是除零，后者的例子可以是在用户模式下执行特权指令</li>
<li>某些特殊指令。这些指令的本身就是产生异常。</li>
<li>intel在P6引入了机器检查异常（Machine Check Exception）。当CPU执行指令期间检测到CPU内部或是外部硬件错误。</li>
</ul>


<p>可见，对CPU来说，中断是异步的，因为CPU完全是被动的指望外部硬件给他一个信号。而异常，则是CPU自己发起，从CPU来看则是同步的。</p>

<p>我们之前已经了解了CPU是如何获知异常，中断。那么CPU接下来的动作又是什么呢？首先需要区分出这些不同的异常，中断。具体则是需要区分出产生中断的来源，8086使用被称为中断类型码的数据来表示中断源。中断类型码为一个字节数据。8086最多可以表示256种中断源。那么接受到各种中断或是异常时，接下来需要做不同处理，那么分别处理中断或是异常的程序入口，叫做中断向量（这里可没有异常向量一回事，这里被统一看待）。而这些中断向量组成一张线性表被称为中断向量表。由于是线性表，我们可以很容易的构造一个类型码到中断向量的映射。</p>

<p>这里还需要强调一点。之前我们提到的异常的分类，那么这些异常的区别是什么呢？既然是控制流的转变，那么就有如何恢复和如何报告控制流转变这2种情况需要我们考虑，而事实上，fault abort trap 就是按照这样划分的。</p>

<ul>
<li>错误类（fault）异常是在产生这个异常指令的指令之前发起。fault通常在执行指令或是执行指令之中被CPU检测到。如果检测到，那么异常将机器的状态恢复到这条指令开始的地方，这样。指令就可以继续执行。可见错误类异常可以无缝继续执行，但是如果没有解决，则会陷入死循环。</li>
<li>陷阱（trap）异常是在产生这个异常指令完成之后，立即产生。那么异常之后的恢复就是引起这条指令的下一个指令（这个是逻辑上的，可不是空间上的）。 可见trap也是可以无缝继续执行。</li>
<li>终止（abort）异常用来报告严重的错误，而这种错误已经严重到不可恢复的地步，也可以说，我们已经不知道该如何恢复了。整个都乱了。比如一些硬件错误。</li>
</ul>


<p>当然到了80386之后，由于保护模式的引入，这部分又引入了各种门，中断们，陷阱门等等，恢复的过程也分了内核态和用户态。而这些个过程，绝大多数书籍都有相关详细的说明，这里不做赘述。有兴趣的同学可以自己翻阅。这里引入这些概念是为了对硬件处理中断有一个笼统的概念，这样会对我们理解OS是如何模拟这个异常过程提供一些帮助。</p>

<p>这里还需要再强调一点，我们可以通过一些指令来屏蔽 可屏蔽中断，事实上，大多数的外接设备都是可屏蔽中断。但是我们的异常确是不可以被屏蔽的。有了之前的基础，我们可以从硬件本身的搭建思考这个原因，也可以从整体设计去思考这样设计的原因。这里算是留个问题吧。我已经觉得我是在是太罗嗦了。</p>

<p>当然这些划分也不是非常精确，有一些错误类异常也是不能恢复执行的。哎，没办法，谁让这计算机是人造的呢。事实上，计算机的世界中充斥着“差不多”，“懒惰”这类思想，如果非要钻严谨的牛角尖只会增加自己的痛苦。因为我们不是在搞数学，有些东西可能背负着我们现在的视野所不能企及的历史问题。所以还是那句话，存在即是道理。我们没有资格对他们评头论足，在我们彻底搞出一个自认为更加合理的东西之前。当然这也是人造科学最让一些喜欢追求完美的家伙们郁闷的地方。呵呵，如果真的有可能，真的应该去拥抱数学。当然人造科学也有好处，是的。他和我们大多数的思维一致，甚至是我们现实经验的抽象，看看计算机的那些最基本的核心概念，stack queue。</p>

<p>差点忘了，还有一个软中断的概念，这里通常指的是INT n这样的指令。如果站在CPU的角度，这个明显是异常，因为这个控制流的转变是CPU内部检测到的。</p>

<p>让我们从茫茫的硬件跳出来。别忘了我们是要了解OS的异常处理。我们可对CPU的世界没有兴趣。是的。正是因为这些硬件太过于底层，而且不同的硬件结构都有不同的地方。那么操作系统如何来保证自己可以在多个这样的硬件平台上执行呢？一个最常见，最通俗的就是OS自己再抽象一个异常，中断。自己定义一个。是的，再没有比自己推倒旧体制，重建新秩序让人更兴奋的了。这样上层的应用就不需要考虑这些细枝末节了。事实上，OS是将这些异常，中断打包在一起管理的。因为他们本质上都是程序执行流程的转换。我们只能看到这是一种“跳转，恢复”而已。所以，现在我们可以忽略掉上面所讲的所有东西。（这里可能会有一种误解，所以我这里叫胡言乱语，要想完全真实的了解这些过程，intel手册，当然如果想要吃下这东西，《机组》《体系结构》….）。</p>

<p>庄子也讲，计人之所知，不若其所不知；其生之时，不若未生之时；以其至小求穷其至大之域，是故迷乱而不能自得也。这些东西还是因人而异。我这里可没有给大家传递必须要学那些硬件知识，或是鼓励大家怎么怎么做。事实上我也没有这个能力，退一步，即使我有这个能力，也没有这个资格。用自己的特例来推广到大家这本身就是一个本末倒置的问题。其实，哎，再加一句废话。存在即是理由，技术本身没有错，错的只是人的角度而已。而这也就是人造科学的悲剧，它不可能让所有人都满意，相反那些只有神才能理解的东西&#8211;数学，不以人类意志为转移。</p>

<p>让我们扯开那些鸡毛蒜皮的东西，静下心来。站在OS的角度来观察异常。那就拿我们最“熟悉”的windows。好吧。windows自己搞了一个异常处理机制。而这里面最熟悉的就是SEH了。当然这不是windows中唯一的异常处理机制。等我们了解SEH之后，再了解他。因为他并不是NT设计之初就存在的。这里可能又要绕绕了。MS真正的操作系统是NT。而95 98 只是dos的一层皮，并不真正算我们想象中的操作系统。</p>

<p>当然NT也搞了自己的一套中断的概念，只是这里。我觉得我们应该暂时放下。在OS，IO处理那部分在来讲述。我觉得这次的硬件有些多了。涉及的太多，反而不能讲述清楚了。</p>

<p>既然我们要弄一个抽象的中间值，那么我们显然只能从异常被CPU识别，然后经过各种机制之后，扔给我们来看的就是NT给我们定义的异常，也是给他自己定义的异常。</p>

<pre><code>typedef struct _EXCEPTION_RECORD { 
    DWORD ExceptionCode; 
    DWORD ExceptionFlags; 
    struct _EXCEPTION_RECORD *ExceptionRecord; 
    PVOID ExceptionAddress; 
    DWORD NumberParameters; 
    DWORD ExceptionInformation[EXCEPTION_MAXIMUM_PARAMETERS]; 
}  EXCEPTION_RECORD;
</code></pre>

<p>EXCEPTION_RECORD 定义异常，更多的可以参考msdn，http://msdn.microsoft.com/en-us/library/aa363082(VS.85).aspx这里只是简单提几点。</p>

<p>ExceptionCode 是NT分配给异常的编码，用来表示是一个什么样的异常。比如我们最熟悉的 0xC0000005 STATUS_ACCESS_VIOLATION。</p>

<p>ExceptionAddress 则表示异常产生的地方。（这里其实是不准确的，如果我们从硬件的角度去看，因为有些地方windows替我们做了一些额外的事情。后面会提到一个例子。）</p>

<p>既然要模拟实现这种程序控制流的转换，那么我们需要提供系统一个函数执行的入口，说白了就是一个函数指针。那么就是下面的这个样子。</p>

<pre><code>EXCEPTION_DISPOSITION 
__cdecl _except_handler( 
     struct _EXCEPTION_RECORD *ExceptionRecord, 
     void * EstablisherFrame, 
     struct _CONTEXT *ContextRecord, 
     void * DispatcherContext 
     );
</code></pre>

<p>让我们先略过这些参数。思考一些问题。我们应该如何注册我们的函数入口，何时解除我们的回调函数。如果站在NT的角度，这些函数入口又该记录在哪里？</p>

<p>最直观的想法就是模仿硬件那种线性设计，搞一张表，来存储这些函数入口。但是我们这种直接想到的，往往都不是真实的设计。我这里只能猜想，由于这些设计都是20年前的东西，过多的访问外部的表，可能会冲击缓存性能。</p>

<p>那么我们怎么做才能在少影响缓存性能的情况下，还能触发程序执行流程转换？而且我们并不知道哪里会出现程序流程的转换。而且由于我们需要模拟这个流程，也就是要支持底层中的中断来让我们普通程序捕获的同时，我们还想要扩展，自定义一些异常来抛出，使得程序流程转换。这个的确是一个复杂的问题。事实上，在我们的程序中已经给我们提供了一个实现这个机制的空间。他就是计算机中里程碑的东东，堆栈。</p>

<p>堆栈是什么时候出现的，这个已经不清楚了。但是可以确定的是现在已经几乎没有能够脱离堆栈而运行的程序。堆栈给我们提供了非常出色的环境。</p>

<p>记录子程序调用轨迹，使得嵌套子程序调用成为可能
通过堆栈传递子程序调用参数，从而简化程序设计。因为寄存器的数目很可能是不够用的。
基于堆栈的程序局部变量的概念得以出现，使得模块化程序设计和结构化程序设计成为可能，也最后导致了进程，线程。
程序执行的轨迹和局部变量结合一起成为“脉络”即上下文。这给我们恢复程序执行，跳转程序执行提供了保障，甚至后面的调度。
我猜想，正是因为SEH的设计和堆栈密不可分，所以才叫“结构化异常处理”吧。</p>

<p>回想一开始的那个带狗狗出去玩的例子，栓链子和解开链子，构成了一段受保护的空间。事实上，编译器在给我们构造可以支持SEH的环境时，也是这样的。进入<strong>try block之前，加保护，在当前程序的堆栈空间中构造一些结构，也就是我们的回调函数入口等其他一些必要的结构。而当我们离开</strong>try block 之后，则就像释放普通的临时变量一样释放掉这些结构体。而且堆栈还有其他的好处，由于我们可以根据堆栈去构造类似printf的不定参数的功能，所以，编译器在支持NT的SEH机制时，可以加入其他一些结构，这样比较方便的扩展和优化这些基本的机制，从而提高效率。减少支持异常的开销。而且事实上，对于异常的开销，如果没有触发异常，现代的编译器已经几乎做到零开销，只是当真正的触发异常时，效率会大幅下降。当然。异常提供了非常强大的转换程序流程的能力，而这也是那些病毒，木马最喜欢的事情。更不说这些相关的SEH结构体就构造在程序的堆栈中，这种没有任何保护的地方。所以需要非常多的安全机制协同保护。而这些问题，大概直到vista后win7才基本上做到了完美，或是那些牛人还没有找到漏洞。</p>

<p>所以说，我们自定义的异常，一般都是程序执行流程中的极端情况，万万不能像理解硬件中断那种思想去理解，也就是异常是不能用来控制程序中大多数流程转变。只能用于极端情况，作为最后的手段。当然，这个可能并不是20年前的那些牛人都能想到的。相关的有关SEH编译器级实现可以参考</p>

<p>Matt Pietrek的文章</p>

<p>http://www.microsoft.com/msj/0197/exception/exception.aspx，</p>

<p>还有我自己写的2篇。</p>

<p>http://www.cnblogs.com/studentdeng/archive/2010/12/15/1907232.html</p>

<p>http://www.cnblogs.com/studentdeng/archive/2010/12/21/1912991.html</p>

<p>原谅我把我的文章和Matt Pietrek的放到一起。当然，这些东西都是最最基础的。</p>

<p>但是这篇可不是去学习具体的实现机制，要明白这个，还是需要一定的汇编基础和多一些的耐心，其实，怎么说呢，对于c的反汇编，主要还是靠耐心吧，没有太多的技术（纯个人感觉，我觉得c++的需要更多些技术）。而且如果再稍微了解一点SEH的安全机制，就会发现，我们似乎又回到了最开始的想法。构造一个表来保存这些回调函数的一些信息。呵呵，事物的发展似乎又回到了原点，但是我们的认识却不在一个层面上了。螺旋发展，也增加了我们学习这些古老东东的难度。真的，有时候真不知道为什么自己会处在这个时代。20年前的操作系统还有人敢说能够比较全面地了解。对于现在的千万级，有的linux甚至是亿级代码量来说。呼呼。穷极一生也仅仅皮毛而已，不过对于计算机这种新科学来说，还能搞个皮毛。而物理，数学那就是还没了解就over了。。。。。。</p>

<p>对比之前的硬件结构，我们已经了解了我们自定义的“异常信号”，“异常向量”。那么我们又是如何根据“异常信号”找到这些“异常向量”呢？那么我们就必须要了解NT的异常触发的模型了。当异常跳出来时，NT的顺序是这样的。（准确说异常在用户态下，关于内核态的我们不管他）</p>

<ul>
<li>调试器 first chance</li>
<li>堆栈上的那些回调函数</li>
<li>调试器 second chance</li>
<li>环境子系统
怎么说呢，我觉得这篇真的好长，环境子系统还是放在OS进程线程那部分了解吧。现在可以把它想象成NT进程的妈吧。反正只要是要创建一个进程都要告她一下。当异常最后也没找到属于他的回调函数，那么就给他妈管教了。当然，NT之所以这样设计异常，就是要构建一个非常强壮的设计。能够将问题层层分类解决。是的，当问题复杂到一定程度之后，虽然我们通常的理解是一步到位会快些，但是事实往往分层更容易开发，维护，管理和甚至是优化。如果不分层，那么想象，搞这么多信息，还需要能支持用户扩展，而且，这个异常处理充斥整个系统本身设计。MS如何能够协同那么多人开发，即使都是天才？</li>
</ul>


<p>整个NT处理异常就是这样的，异常来了，OS先找debugger，debugger不管，那就在程序堆栈上找人，也不管，唉，debugger你还不管？ 好吧，subsystem你搞定吧。对于这种谁都不管的异常，正式一点的叫法是未处理异常，这个也其实是比较复杂的，因为2K， XP，vista的策略都不同。策略本身不复杂但为什么不同？ 有机会的话，需要再深入一点学习一点。</p>

<p>这里面对大多数同学，如果不了解汇编的话，可能无法理解这个调试器为什么要跑2次？要知道我们现在可是在和效率赛跑，而且为什么调试器首先要捕获异常？而不是我们本身的程序？</p>

<p>我们想一个问题。在我们使用debugger调试程序的时候，我们的程序凭什么能够加入断点，然后停下来？CPU执行可是老老实实的按照一条条的指令跑的，没有那些花花肠子。当我们单步调试的时候，为什么程序执行一条指令（我这里指调试汇编代码，调试c，c++这些还需要稍微麻烦一点）就要停下来呢？当我们有了中断的概念就不难理解这个问题了。是的。就是发生了中断。导致CPU暂停了当前被调试进程，而把控制流转向到了debugger。那么怎么暂停？为什么能够暂停？这个还是交给OS的调度和同步那里再学习吧。</p>

<p>事实上，这个断点（我说的这种）就是指令INT 3。他可以说是我们非常熟悉，但又陌生的。不知道大家在一开始用c编程的时候，至少是我自己，在辛苦了半天之后，一运行发现屏幕上跑出一大堆烫烫烫烫。事实上，他就是INT 3。</p>

<p>INT 3的机器码是1100 1100b（0xCC）。一个字节长。编译器在debug下会给我们创建额外的栈空间并填上INT 3，至于为什么这样，我这里就不啰嗦了。这种纯菜鸟错误，通常是没把指针玩明白。有点远，呵呵，为什么扯这么远，是因为在有了之前的硬件知识，这里很可能产生疑问。看这个指令的样子，我们发现他是个软中断，或称为trap。那么根据之前所讲的，这里的异常地址应该是这条指令的下一条。但是我们这里看到的却是我们打断点的这条指令。那么要搞清楚这个，又要稍微绕绕下。当我们加入一个断点的时候，vc会自动记录下我们这个断点的位置信息。当调试的时候，vc会把这些断点位置处的指令换成我们的INT 3。也就是替换掉一个字节。当然，替换之前要保存原来的。这个过程叫做落实断点（resolve break point）。那么当CPU执行到INT 3指令时。是的。这时我们就明白了，为什么要先让调试器捕获异常了。这些东西要是先给了我们做，那么调试器就没法子实现功能了。然后就是一系列的硬件，OS的事情。vc把之前我们的代码再恢复过来。所以这也就是RtlRaiseException产生的软件异常并不会先扔给debugger first chance。因为我们自己搞得东西是不可能和debugger有任何关系的。</p>

<p>我们这里需要特别关注下NT干的事。</p>

<p>对于NT来说，INT 3 会导致CPU执行KiTrap03程序。（为什么执行这个，我们在IO那里再了解）。在WRK中，我们可以看到这部分的源代码。这里不得不提MS，不知道哪个脑子别了改锥的人想出了一个这么限定，代码不能超过50行。无语。</p>

<pre><code>mov     esi, ecx                ; ExceptionInfo 2
mov     edi, edx                ; ExceptionInfo 3
mov     edx, eax                ; ExceptionInfo 1

mov     ebx, [ebp]+TsEip
dec     ebx                     ; (ebx)-&gt; int3 instruction
mov     ecx, 3
mov     eax, STATUS_BREAKPOINT
call    CommonDispatchException ; Never return
</code></pre>

<p>不管怎么说，人家总是做出贡献了。我们看到了dec ebx。是的。在处理异常的时候，nt这里修正了一下，而那个1，就是INT 3这条指令的长度。现在我们就明白为什么我们能正确看到我们的代码了。也验证了trap的流程。</p>

<p>绕了很远，把思路拉回来。</p>

<p>让我们再思考一个问题，程序流程突然转变了，甚至可能永远回不来了，而且我们现在的代码是看不出这个状态。也就是我们随时都可能被别人抢了。哎，可惜啊，咱们处在最底层。人为刀俎，我为鱼肉。但是NT还是比较有人性的。而且这也是很有必要的。在程序流程突然转变了。在保护的这段代码中，可能有一些关键的操作没有做。比如内存释放，一些同步的锁等。但是由于某种未知原因，我们只能放弃这部分操作。那么我们的这部分被动代码什么时候执行呢？而且，由于这些保护的代码很可能由于函数调用，在形式上或是非形式上，都可以形成一个嵌套的关系。这些释放的顺序，从那里开始释放，释放到哪里？这都是NT需要给我们规划好的。</p>

<p>不要被我复杂的言论迷惑，实际上整个过程很简单。因为我们程序的执行流程信息都在堆栈上。我们根据堆栈信息我们可以很容易找到起点和终点。那么从问题出发点，到结束点。我们便走了2次。第一次从出发点到结束点，这是为了找到处理程序。第二次则是叫做stack unwind，栈展开。 从出发点到结束点。当然这个过程中，依然有很多更复杂的问题。异常查找时很可能产生死循环。unwind的过程也可以被随时中断或是走到其他地方。而导致我们写的那些备用代码无法执行。事实上NT给了我们非常多的选择。vc只是披了一层皮。</p>

<p>SEH就像ReactOS上写的一样，“SEH is a game which is played between OS and Compiler (Keywords: <strong>try, </strong>except, __finally)。</p>

<p>写在最后</p>

<p>我发现我越来越罗嗦了。絮叨絮叨的像个大妈。
后面的部分依然有点穿越。在不谈具体实现的细节下去说清楚SEH的基本过程，对我还是太复杂了，应该是我还没有理解透彻，慢慢来吧。具体过程可以参考我推荐的3篇文章，当然。最好的方法是自己推导。
我真的不知道这篇文章是写给自己还是写给别人看的。是的。如果我是读者，当我看到这篇文章的时候，我真想向这个作者扔砖头。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2011/02/03/algorithms/">算法学习二三事</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-02-03T23:02:00+08:00" pubdate data-updated="true">Feb 3<span>rd</span>, 2011</time>
        

        
      | <a href="/blog/2011/02/03/algorithms/#comments">Comments</a>
        

      </p>
    
  </header>


  <div class="entry-content"><p>不得不说，有时候无知是福，看到一点有趣而深刻的东东，就能感觉到神奇。越是我们熟悉的东西，往往却是我们进一步理解深刻的障碍，而之所以是障碍是我们并不知道这个是我们理解问题的障碍。困惑中的每一次豁然开朗往往是从一点一滴的我们已经成为惯性思维中开始。越是深刻的原理，往往越是简单强大。就像爱因斯坦打破牛顿给我们原有的世界观一样。对于一个打破常规，让你重新理解问题的最简单的方法就是把你整个思考的前提否定。而带来的结果就是我们看问题的角度，层面有了更大的扩展。所以，有时候知道的太多反而不美，做一个白痴也很幸福。</p>

<p>哎，又无病呻吟了半天。之所以有上述感想。还得感谢自己的同学。由于我没有看过MIT的经典课程《算法导论》而被鄙视，而且更无语的是，我的理由是“听不懂，如果有老师的课堂发音的记录”，而事实上。这个MIT早就提供了，为了照顾想我这样的听力不好的家伙。好吧，我是个白痴，不过就像上面讲的，白痴也有白痴的幸福。这个假期，无聊的时候，不仅可以看《爱情公寓2》也可以屡屡自己的数学常识了。：）</p>

<p>《算法导论》是一名研究算法设计的课程。设计算法，我们关心的主要是2个方面，一个是性能，另一个是资源花费。当然，我们重点的是性能，我们总是希望我们的程序跑的更快。那么学习算法到底有什么用呢？这是一个经典的问题。Charles Leiserson 是这样给我们解答的。首先，列举了一大堆在实际编程中比性能更重要的东西：可维护性，模块化，功能，用户体验等等。特别是用户体验，那么既然有这么多的东东比算法重要，那么为什么我们还要学习算法呢？</p>

<h2>算法决定了可行还是不可行。</h2>

<p>在一些实时的情况下，比如机器人等嵌入式设备，我们不够快，那么就没有意义，如果我们用了太多的内存，同样不行。所以，算法这个东东，总是在我们计算机领域的最前沿部分，如人工智能，搜索引擎，数据挖掘。如果我们是在做10年前就已经实现了的东西，那么性能的确在一些情况下已经不重要了。但是，如果想做一些别人没有做过的东西，真正的实现从无到有的过程。那么其中遇到的绝大多数问题都是，数据太复杂了。没有能力在有限的资源下找到答案。这也就是为什么叫计算机科学，而不是计算机工程。（当然科学这个和名字是无关的，比如物理，从来没有那个学校叫个什么物理科学什么的。：））。不得不说，MIT的目标是为世界培养leader，而我们那破学校是为了培养farmer（这里并没有不敬在里面，而且事实上，做一个farmer挺好的，每年坐在家里，收个房租，年末村里再分个几十万，比那些城里白领好多了在物质上）。其实也不那么绝对，非要改变世界，只要是之前没有做过的程序，我们在实现之前，首先思考的一定是算法。其次，则是对他不断的优化，完善。</p>

<p>对绝大多数的刚刚参加工作的同学，往往不能体会到整个产品的创建过程。参与的仅仅是完善，算法的设计或是大体设计已经完成，所以感觉不到算法的存在。而匆匆下了学校白学的定论。而随着工作时间变长，总会遇到没有或是不能直接利用原有设计的东东，那么算法也就体现出价值了。</p>

<h2>算法是一种描述程序行为的通用语言。</h2>

<p>我们可以通过算法去描述程序的运行流程，在任何地方。他不仅能在实践中得到体现，也能在理论中得到证明。而且能够得到大家一致的看法。而这是别的永远无法做到的，比如用户体验，每个人都有自己的想法，我们不可能让所有人都满意我们的设计，而算法却可以做到，因为快就是快。放到计算机上一跑结果自知。别人无法击败你，即便是再挑剔的对手，只要你足够出色。而能够满足这样条件的前提就是，算法是一个如此一般化，基础的东西。就像Charles Leiserson 所讲，算法就像钱，你可以用钱去买吃的，喝的。而衡量这些花费的就是钱的数目。在计算机上，则是，选择一个这样的策略，需要花费多少。选择另一个策略，需要花费多少。而衡量这2个选择谁的花费多呢？是算法。</p>

<p>算法在计算机中的地位，就和数学在所有理科学科中的地位一样。我曾经问过我的数学老师一个问题，他的回答让我直到现在还记忆犹新。“老师，数学在您眼中是什么呢？”“数学是所有理科中是最奇妙的一个。因为他可以独立于其他任何学科存在而其他学科离开不了数学。”是的。能够想象物理化学离开数学之后是什么样子么？但是数学为什么能够独立存在？是因为他构建了一门语言，一门伟大的语言。使用这门语言可以让知识在任何领域中环绕，学好数学就好像有了一张无限透支的通用支票，可以在任何地方花费（黄金？）。作为一个可以让这么多地方都通用的原因中最重要的就是，他是超级稳定的。是一个说一不二的世界。一个公平的世界，绝对的世界（当然，现在数学这个概念也不准确了，这个充分体现了哲学思想，有正必有反啊：P）。他所确定的东西的结果是肯定的。没有歧义，而且不随时间变化而流动。比如，我们真实世界中交流的语言，比如“忽悠”，“猥琐”。等等。很多词义，随着时间的变化而改变了。使得很多年纪大的人，和我们这年轻人在交流上就产生了隔阂。而我们最熟悉另一个例子就是文言文，特别是其中的一些扭曲的字。但数学这种基础类学科是不会的。至少在一个可以预见的范围是稳定的，没有地域限制的。所以，数学才能站在人类科学发展的最前沿，他的每一次前进的一小步，都能改变世界。这就是数学之美。同样也是自己能够让绝大多数人接受的最大障碍。由于他改变的太慢，而且枯燥。绝大多数人无法深入的理解。当用世俗，腐烂，充满铜臭，功利的眼光看待纯净的数学世界，必然发现数学无用。而且，这的确是事实，因为大部分人，都不可能成为改变世界的家伙（这里的确不准确，因为改变世界话题太大，修理地球同样也是改变世界。）。</p>

<p>算法，同样为我们计算机构建了一个纯净的世界。一个说一不二的世界，他所确定的，没有能够反驳的。当然，就和学习数学一样，我们不是去成为数学家，学习物理，不是去成为物理学家，然后去做哪些能够改变世界的东西。学习这些基础类学科的重要在于，他提供了一个让我们和那些站在人类史上最顶尖的家伙们交流的语言，从我的角度来看。如果没学好数学，能够和牛顿，爱因斯坦交流么？没有学好算法，能够和高爷爷交流么？作为一个普通人，我们只要学习到他们身上的一点点，也就足够了。当然，这不是对所有家伙都有效，有些人总是想，和那些老家伙有什么好交流的，给我一个周杰伦的签名吧。：）</p>

<h2>学习算法还有一个原因，是的，就是兴趣。这个传说中最牛X的老师。</h2>

<p>喜欢算法，没有别的原因，是的。我就是喜欢比别人快速的感觉。喜欢数学，是的。因为大部分人数学不好。所以我就喜欢数学。迎难而上，哥就是喜欢做别人做不了的东西。是的，虽然听上去很牵强，而且比较扭曲。比较符合印象中90后的想法。不知道90后是不是能产生更多的数学家呢？</p>

<p>让我们回到我们的算法上，既然我们这么关注性能，那么什么是影响性能的因素呢？</p>

<p>对于一个计算机外行来说，首先就是计算机硬件本身的运算能力。多一个超级牛的CPU，超大的内存，固态硬盘。肯定运算快。的确，如果你拿一个超级计算机和地摊上买的一个小的计算器比运算能力。这个实在是一个很显然的结果。是的，所以，我们有些情况下，需要思考在相同条件下，到底哪个算法的性能更高。这比较的是相对速度。但是我们却不能忘了这一点。有时，我们想使用一些很一般的计算机，通过优秀的算法，来打败那些拥有更高硬件的那些家伙们，而我们则必须关心算法性能的绝对速度。那么我们该如何描述这些看似互相矛盾的东西呢？不要忘记，算法可是基础啊，我们要的是一个确切的答案。我们如何给出一个确切的答案，而这个答案不管是超级计算机，还是普通PC都能够支持呢？这就是算法中最重要的一个概念，甚至是一切分析的大前提，一个可以把这些复杂的因素都考虑在内（或是都不考虑在内）的东东转换为可以用数学分析的对象。这就是渐进分析。</p>

<p>渐进分析的基本思想是</p>

<p>忽略硬件结构</p>

<p>不使用真实世界的运行时间，而是关心运行时间的增长速度为对象</p>

<p>渐进分析是一个非常庞大的概念，我们最熟悉的，也是大多数本科院校教我们的就是Θ,O,Ω等等类似的这些符号。这里只从Θ开始。</p>

<p>对一个初学者，Θ-notation是比较容易接受的。对一个多项式，我们只需要删除掉所有的低次幂项，忽略掉常数，系数这些次要因素。就和Charles Leiserson 所讲的。这个描述，是工程方向的描述，并不是严格的数学上的定义。而对像我这样的小白来说，最大的误解就是把他当成了数学上的严格定义而产生了极大的困惑。</p>

<p><img src="/images/algorithms.png" alt="alt text" /></p>

<p>这个是一个相当经典的图，当n趋于无穷大时，Θ（n3）总能干掉Θ（n2）。不管是同样的硬件设备，还是不同的硬件设备。只是在不同的设备下，不同的算法下，我们有了一个不同的系数，低次幂项，和常数。但是，我们关心的是他随着数据输入长度的变大而产生的增速。当n超过n0时，任何的次要因素都是浮云了。我们就可以说Θ（n3）被Θ（n2）干掉了，即使Θ（n3）的硬件要比Θ（n2）好很多，在一开始的时候效率有多高。</p>

<p>这是一个伟大，cool的概念。是的，他完美的既满足了我们追求的绝对速度，也能满足我们追求的相对速度。可以说，这给了我们继续学习算法的动力。但是，事实上，在实际开发中，我们有时候却使用那些在学校中认为是效率低的算法。难道这个理论错了？当然不是，错的是我们，我们忽略了一个很大的前提，n0。在我们多数开发过程中，很少接触那些海量数据的运算。我们的运算多数是在一个较少的数据上下浮动，这个也可以说我们的硬件，资金，产品，根本不需要我们整那么大的数据。也就是n0，我们根本达不到。事实上，只要是有脑子的，看到这个图，在小于n0的前提下，都会做成正确的判断。但对于刚刚步入IT的广大学生，却总是犯下屁股决定脑袋这样愚蠢的选择。而这其实，就是做科学和做工程师的最大区别。理论和实践相互掰手腕的结果。</p>

<p>这几天，挖老赵的“坟”，找出了这么一篇。<a href="http://www.cnblogs.com/JeffreyZhao/archive/2009/05/29/1491692.html">写程序时该追求什么，什么是次要的？</a>里面有一段十分搞笑的代码，之所以这样说，是因为我自己也写过这样的代码。想想真是dt啊。回想事发现场，我记得是我看了个什么类似《面试宝典》东东，有一些题考察交换元素，事实上，你可以找到一大堆的，而且是更精妙的去交换2个元素。看到之后，如获至宝。只要是2个元素要换位置，就用。站在做科学的角度上看，这无可厚非。但是如果站在工程的角度来看。这就是明显的画蛇添足。往往花费80%的精力在提高%20的性能上，而不是去花费20%的精力提高80%的性能。这同样是刚刚步入IT的广大同学的问题。做科学需要严谨，但是在工程方面，考虑的事情非常复杂，多。我们必须要关注在核心，关键的部分。这样才能在有限的资源下，最大的做出东东来。实践中，没有任何项目的资源是足够的。MS，Google都会有资源不足的时候。我们需要学会抓住重点。当然这里并没有鄙视这些面试问题，事实上，这些问题的背后往往是考察数学思维的基本功，而不是鼓励大家这么做。就像那个经典的问题，12个小球一架天平。没有仔细，严谨的思考，能够想到这个东东能和排序问题扯上勾么？神啊，万恶的功利，给完美的数学模型批了一层邪恶的外套，使我们在追求本质的过程中迷失。</p>

<p>有关n0的问题，不仅在算法设计上，也出现在我们的设计模式之中。《设计模式》这本神书，我是没看过，也不敢看。但也隐隐感觉到类似“设计过度”的言论。这同样都是在理论和实践结合上出了问题。当然，不少理论支持者，肯定会说，那是因为你没做过那么大的项目。但事实却是，不管设计多么复杂的，还是多么简单的，实践和理论永远不可能都得到满足。windows操作系统可以说是一个我们可见的最大的项目之一了。但是windows也并不是一个微内核，在内核中也绑定了非常多的“多余”的部分从理论上看。那无疑会降低系统稳定性，提高维护难度。但是我们却不能不说windows是最成功的一套软件之一（这个之一甚至都可以去掉）。</p>

<p>当然，要想在做学问和实践找到平衡点。这个无疑是极大的挑战。只是分析理论，而不实践，那么永远不可能成为一个出色的工程师。除非你的目标是成为理论科学家。反过来，如果不理论而只是实践，不同的是，这个是可以成为一个出色的工程师。所以，这里有一句经典的话。</p>

<p>If you want to be a good programmer, you just program ever day for two years, you will be an excellent programmer. If you want to be a world-class programmer, you can program every day for ten years, or you can program every day for two years and take an algorithms class.</p>

<p>既然算法是如此的重要，那么我们该如何学呢？其实，这是一个很纠结的问题。甚至是一个鸡生蛋，蛋生鸡的问题。不学算法，你不会了解他，也不会认识到算法重要，反而。认为算法不重要，那么也就不会下功夫去学。这就又回到一开始的那个unknown unknown上了。所以，如果准备学习算法，也就意味着选择了一条坎坷的路。一开始特别迷茫，但是没有别的选择。唯有坚持，放下浮躁，功利的心态，沉浸在数学的世界中才能体会到数学的价值，数学的乐趣。也只有这样，才能坚持到最后。</p>

<p>当然，能做到这一点的，敢说体会到数学之美的家伙，全世界也没有几个人。那么作为一个普通人，我们怎么才能最大的去提高自己，更好的掌握实践和科学的平衡点呢？这个问题，我自己也没有答案。因为我既没经验又没理论。这里只是扯下我自己的理解，可能很偏激。</p>

<p>首先应该研究下<a href="http://mindhacks.cn/author/pongba/">刘未鹏</a>的很多博客内容，特别是<a href="http://mindhacks.cn/2009/01/16/hammers-and-nails/">锤子和钉子</a>。对我这样的新手来说，武器真的太少了。所以当捡到一个武器往往过于兴奋而忽视了这个武器的使用前提，往往杀鸡用牛刀，而且还达不到积极的效果。就是因为我们拿到锤子之后，所有东西看上去都像钉子。所以，我们唯有摆正心态，深入了解拥有的武器，并增加更多的武器，见更多的市面，才能坐怀不乱，达到手中有锤，心中无锤的最终境界。</p>

<p>一个稍微实际的例子。对像我这样的菜鸟来讲，大部分都会遇到这样一个问题。而且困惑很久很久。“堆排序为什么比快速排序在大多数时要慢呢？”事实上，造成这个问题的主要原因（对我）就是，没有理解明白Θ-notation。那些被忽略掉的次要因素，当然还有更重要的是数学上对概率的薄弱理解。然后我们会再映射出一大堆的数学基础知识，然后大部分人死在沙滩上（真的，这是我从小以来最大的遗憾，就是没有学好概率，而造成这个的原因居然是，这些题目初学时往往是用日常用语出题，而由于本人语文太差，总不能理解清楚题意，而对这类题目产生了极大的抵触，可见小朋友们千万不要偏科:P）。从科学的角度去，完全可以证明这个问题，但是付出的代价就是没有硕士以上的数学能力的玩家，没有机会理解到那个层次。那么，其实我们可以从另一个角度看，直接放到计算机上跑一下就可以了么。是的，我不是科学家，我只需要知道结果就OK了。是啊，好在我们处在一个和谐的世界。让我们从这个庞然大物中得以解脱，所以，有时，我们需要根据自身情况，放弃一些东西，特别是那些比较能够通过实验来证明的东西。</p>

<p>好吧，总不能啥也放弃吧，都放弃了那到底也简单了。这里，我只能说，我推荐SGI STL。在我看来，这是一个结合了设计模式，理论算法与实践最好的一个实例。他不仅是开源的，代码量也不多，命名也算规范，而且还有一本侯捷大师的著作来诠释，帮助我们理解，而且还能帮助我们具体实践过程中规避一些错误。我们每一个在学校学习的算法，我们都可以在这里找到答案（至少可以用来做作业拿高分对某些特别的女生），而且都会比一般大学讲的深刻，事实上，我认为，大学现在的教育为什么觉得无用，不是太难太理论，而是教的太简单了，简单到已经没有用的地步了，从而根本没有实际意义。（大学联合培训机构，是我所见过的，比大学扩招还要搞笑的事情）比如快速排序，SGI STL做了非常多的优化来保证无论在什么时候，都不会退化到n2，在分的过程总是分不好时，采用堆排序。在快速排序到做最后几步，为了减少开销而采用插入排序去做哪些马上就要排好序的部分。而这些策略，并不是凭空想象，都可以在高爷爷的著作中找到理论证明，以及网上的各种论文，前提是你的数学功底足够（当然这里实践在前还是理论在前这个实在是没有讨论的意义）。所以，理论不是没有用，只是自己学的太肤浅。实践也不是没有用，只是自己没有考虑那么多的情况，想的太简单而已。</p>

<p>当然，这个可能又会引起另一个庞大的问题，“不要重复制作轮子”，不过这个已经大大超出这篇文章的范围了。我自己的看法是，STL是为了实现最基本的最通用的东东的，而实际过程中，我们往往有自己的特殊性。而这些特殊性是STL不可能设计时都给我们考虑周全的。也就是我们很可能需要扩展，重写部分以适合我们的需要。当然，现在离这些目标还很远很远很远。</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/6/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/blog/page/4/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Categories</h1>
  <ul id="categories">
    <li class='category'><a href='/blog/categories/ios/'>IOS (1)</a></li>
<li class='category'><a href='/blog/categories/objective-c/'>Objective-C (6)</a></li>
<li class='category'><a href='/blog/categories/stl/'>STL (5)</a></li>
<li class='category'><a href='/blog/categories/wpf-sl/'>WPF/SL (1)</a></li>
<li class='category'><a href='/blog/categories/algorithms/'>algorithms (8)</a></li>
<li class='category'><a href='/blog/categories/apple-script/'>apple_script (1)</a></li>
<li class='category'><a href='/blog/categories/asm/'>asm (1)</a></li>
<li class='category'><a href='/blog/categories/c-/'>c++ (6)</a></li>
<li class='category'><a href='/blog/categories/configure/'>configure (2)</a></li>
<li class='category'><a href='/blog/categories/emotion/'>emotion (11)</a></li>
<li class='category'><a href='/blog/categories/mysql/'>mysql (2)</a></li>
<li class='category'><a href='/blog/categories/notes/'>notes (1)</a></li>
<li class='category'><a href='/blog/categories/operating-system/'>operating_system (3)</a></li>
<li class='category'><a href='/blog/categories/tips/'>tips (2)</a></li>
<li class='category'><a href='/blog/categories/windows/'>windows (9)</a></li>
<li class='category'><a href='/blog/categories/windows-mobile/'>windows_mobile (2)</a></li>

  </ul>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2013/06/24/remember/">唯一有益的怀旧是想像未来的自己怀旧现在</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/06/20/something-should-already-known/">一些早该知道的东西</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/06/12/note-book/">《20个月赚130亿》笔记</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/05/08/code-snippets/">code snippets</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/04/24/apple-script-1/">Apple Script 可执行的伪代码</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/studentdeng">@studentdeng</a> on GitHub
  
  <script type="text/javascript">
    $.domReady(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'studentdeng',
            count: 5,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>





<section>
<h1>Recent Comments</h1>
<ul class="ds-recent-comments" data-num-items="5" data-show-avatars="0" data-show-time="0" data-show-title="0" data-show-admin="0" data-excerpt-length="18"></ul>

<!--多说js加载开始，一个页面只需要加载一次 -->
<script type="text/javascript">
  var duoshuoQuery = {short_name:"studentdeng"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = 'http://static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
</script>
<!--多说js加载结束，一个页面只需要加载一次 -->

</section>
  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2013 - studentdeng -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  











</body>
</html>
