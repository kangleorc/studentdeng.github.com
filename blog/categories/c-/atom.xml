<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: c++ | studentdeng Blog]]></title>
  <link href="http://studentdeng.github.com/blog/categories/c-/atom.xml" rel="self"/>
  <link href="http://studentdeng.github.com/"/>
  <updated>2013-03-03T18:51:26+08:00</updated>
  <id>http://studentdeng.github.com/</id>
  <author>
    <name><![CDATA[studentdeng]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[多线程程序设计笔记二]]></title>
    <link href="http://studentdeng.github.com/blog/2010/04/24/mult-threading2/"/>
    <updated>2010-04-24T18:46:00+08:00</updated>
    <id>http://studentdeng.github.com/blog/2010/04/24/mult-threading2</id>
    <content type="html"><![CDATA[<p>当我们正式开始之前，我想再多说一点，上一篇最后的那个程序可能会给像我一样的菜鸟一个误解，这里解释下。</p>

<p>程序启动后就执行的那个线程称为主线程（也就是那个程序中的执行main函数的线程），而其他线程则成为子线程。主线程和其他线程最大的区别是当主线程返回或是调用一些函数强制退出后，使得程序中的其他子线程强制结束。 在一篇中native code和Manager code 在遇到同样的问题时，.net给我们做了一个好的榜样，其实不管是否是UI子线程，.net 控制台在终止进程结束之前，都会保证所有子线程已经退出。虽然我们无法知道到底它采用的是什么机制（我的理解是在调用结束进程之前调用了WaitForMultipleObjects或是其他wait函数等待所有子线程返回），但是这体现了一个很重要的原则，对产生的子线程负责，无论什么时候，都不应该直接结束程序而不等待子线程结束。因为子线程没有机会做清理工作。这个是一个非常可怕的问题，想这样的一个情况，子线程比如正在申请一个堆空间，而正好锁住了那个区域，然后被强制结束了。那么就很可能产生了内存泄露（产生不了也会增大系统负担）。所以再次提醒自己主线程在退出的时候，必须保证所有的子线程已经退出。</p>

<p>从上一篇《多线程程序设计笔记一》中，我们知道了多线程程序设计的最基础的知识。下面总结下线程之间的通讯和同步问题。不过这个问题实在是太大了，对我来说。这里先只涉及最简单的在同一进程下的用户方式下的同步问题。</p>

<p>以下内容将包括：</p>

<p>互锁函数
临界区
互锁函数</p>

<p>互锁函数运行在用户模式。它能保证当一个线程访问一个变量时，其它线程无法访问此变量，以确保变量值的唯一性。</p>

<p>下面是一个简单的例子。</p>

<pre><code>DWORD WINAPI ThreadFunc1(PVOID n)
{
  while(InterlockedExchange(&amp;g_bResourceInUse,TRUE) == TRUE)
    SwitchToThread();
  printf("thread1 used\n");
  InterlockedExchange(&amp;g_bResourceInUse,FALSE);
  return 0;
}
DWORD WINAPI ThreadFunc2(PVOID n)
{
  while(InterlockedExchange(&amp;g_bResourceInUse,TRUE) == TRUE)
    SwitchToThread();
  printf("thread2 used\n");
  InterlockedExchange(&amp;g_bResourceInUse,FALSE);    
  return 0;
}
</code></pre>

<p>这个例子通过不断地判断bResourceInUse中的信息来确定线程是否能够使用资源。但是使用这个方法必须小心。大量的循环运算会浪费宝贵的CPU时间。而且如果是在单CPU下，线程不可能真正的异步执行，在thread1判断while的时候，thread2并不能做什么（不能修改该值）。所以我们应该避免在单个CPU计算机上使用循环锁。</p>

<p>这里面还有一个需要知道的是必须使用关键字volatile声明g_bResourceInUse。我们需要把循环锁变量和循环锁保护的数据维护在不同的高速缓存行中。通过高速缓存行CPU可以不必访问内存总线而获得数据，但是在多处理器环境中，高速缓存行使得内存更新更加困难。如下：</p>

<p>CPU1读取一个字节，将该字节和相邻字节读入CPU1的高速缓存行。
CPU2读取同一个字节。从而和第一步相同的内容读入了CPU2的高速缓存行。
CPU1修改该字节，因为已经在高速缓存行中，所以修改后的内容写入CPU1的高速缓存行，这个信息还没有写入内存。
CPU2再次入去同一个字节。因为已经放入了CPU2的高速缓存行，所以CPU2不会访问内存。那么问题出现了。这个字节并不是该字节的新值。
这个问题的确很严重，不过硬件工作者已经给我们解决了这个问题，当一个CPU修改高速缓存行字节时，其他CPU会被告知这个情况，他们的高速缓存行将无效。所以第四步中，CPU1必须将高速缓存行转入内存，而CPU2必须再次访问内存。</p>

<p>原因想说清楚这些我现在还不行，这又涉及到了多核编程（哎，愧对老师啊，《多核程序设计》那课是白学了）。不过这里还是必须解释下volatile。</p>

<p>被定义为volatile的变量，每次从内存中读取，而不能把他放在cache或寄存器中重复使用。
告知编译器不要对这个变量做优化。
告知编译器，变量可以被应用程序本身以外的某个东西进行修改，这些东西包括操作系统，硬件或同时执行的线程等。</p>

<p>当必须以原子操作方式修改32为，64位值时，我们可以使用互锁函数。他们很有效率。但是实际工作，我们需要面对更复杂的数据结构。而且他们的效率是不进入内核态而节省下的。如果等待资源时间过长，就变成对CPU极大的浪费了，我们需要一种机制，使线程在等待访问共享资源时不浪费CPU时间。</p>

<p>临界区（Critical Section）又叫做关键代码段</p>

<p>临界区的描述</p>

<p>win32提供的一种轻量级的同步机制，它存在于进程的内存空间中。一次只有一个线程获准进入临界区执行代码段，（其实就是让若干行代码能够以原子操作方式来使用资源）。
它并不总是执行向内核模式的控制转换，要是获得一个未被占用的临界区时，只需要在用户态内的很少运算就能完成，只有在尝试获得已占用临界区时，它才会跳至内核模式。
只能在属于同一个进程的线程间同步。
补充一点，比如当线程A试图进入线程B拥有的临界区时，线程A将被置于等待状态。线程B离开临界区，线程A将处于可调度状态。让线程A立即等待，并不一定立即切换到内核方式。MS为了提高关键代码段的运行性能，将循环锁加入了这些代码段。当调用 EnterCriticalSection 它使用循环锁进行循环，只有当每次尝试获取都失败时才转入内核方式，从而线程A进入等待状态。</p>

<p>这里可能就又糊涂了。之前说的循环锁不是效率很低么？的确，但是如果和转入内核方式比所消耗的资源少的话，就是可行的。比如我们仅仅是想操作一个指针。当然，如果是在单CPU下，循环锁是没有意义的，会直接转入内核方式。</p>

<p>临界区的使用方法</p>

<pre><code>    通过 InitializeCriticalSection 或 InitializeCriticalSectionAndSpinCount 函数初始化一个 CRITICAL_SECTION 结构，使用 SetCriticalSectionSpinCount 函数设置临界区的Spin计数器（可选）。然后使用 EnterCriticalSection 或 TryEnterCriticalSection 获取临界区的所有权；完成需要同步的操作后，使用 LeaveCriticalSection 函数释放临界区。最后使用 DeleteCriticalSection 函数析构临界区结构（只是删除RTL_CRITICAL_SECTION_ DEBUG）。
</code></pre>

<p>讲了这么多理论，实践一下。</p>

<p>下面是对上一篇List做的多线程改进。</p>

<pre><code>typedef struct _Node
{
  struct _Node *next;
  int data;
}Node;
typedef struct _List
{
  Node *head;
  CRITICAL_SECTION sec;
}List;
List *CreateList()
{
  List *pList = (List *)malloc(sizeof(pList));
  pList-&gt;head = NULL;
  InitializeCriticalSection(&amp;pList-&gt;sec);
  return pList;
}
void DeleteList(List *pList)
{
  DeleteCriticalSection(&amp;pList-&gt;sec);
  free(pList);
  pList = NULL;
}
void AddHead(List *pList,Node *node)
{
  EnterCriticalSection(&amp;pList-&gt;sec);
  node-&gt;next = pList-&gt;head;
  pList-&gt;head = node;
  LeaveCriticalSection(&amp;pList-&gt;sec);
}
</code></pre>

<p>当然事实上没有这么简单。比如当交换两个链表内容的函数</p>

<pre><code>void SwapLists(List *list1,List *List2)
{
  List *temp_List;
  EnterCriticalSection(list1-&gt;sec);
  EnterCriticalSection(list2-&gt;sec);
  tmp_List-&gt;list = list1-&gt;head;
  list1-&gt;head = list2-&gt;head;
  list2-&gt;head = temp-&gt;list;
  LeaveCriticalSection(list1-&gt;sec);
  LeaveCriticalSection(list2-&gt;sec);
}
</code></pre>

<p>当threadA: SwapLists(list1,list2);threadB:SwapLists(list2,list1)。两个线程会落入“我等你，你等我”的轮回，这种情况称为死锁。</p>

<p>任何时候当一段代码需要1个以上的资源时，都可能发生死锁。而我们防止死锁通常的做法是保证“all or nothing”，也就是要不全部拥有，要不什么也没有。</p>

<p>其实上面的代码还隐藏了一个问题，SwapList函数在使用的时候无形的需要确保一个资源使用的顺序。也就是说这个函数的运程依赖于代码的执行顺序，这种设计本身就是很脆弱的。</p>

<p>临界区需要注意的</p>

<p>每个共享资源使用一个CRITICAL_SECTION。只有被临界区Enter和Leave“围起来”的资源才能获得保护，临界区维护的只是一段代码（代码中通常有一些资源）。
当同时访问多个资源的时候，使用临界区非常容易造成死锁， EnterCriticalSection 的顺序是需要认真考虑的但是并不一定十分可靠， LeaveCriticalSection 顺序则没有关系。
不要长时间运行临界区，也就是不要长时间锁住一个资源。但是时间到底多长很难确定在windows OS中，所以不要在一个CRITICAL_SECTION中调用Sleep或Wait….API函数，SendMessage。当你以一个同步机制保护一份资源时，必须牢记“这项资源被使用频率如何？线程必须多块释放资源，才能确保整个程序运作平顺”。
无法获知进入临界区的线程状态。由于临界区不是核心对象，如果一个线程进入临界区后，没有Leave，系统没有办法清除临界区。而且如果一个线程在Enter时被等待，那么等待的最长时间也是不能设定的。（也减少了一个处理错误的方式）
想要了解更多的关于临界区的，参考http://msdn.microsoft.com/zh-cn/magazine/cc164040(en-us).aspx</p>

<p>中文http://www.microsoft.com/china/MSDN/library/enterprisedevelopment/softwaredev/ousCriticalSections.mspx?mfr=true</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[多线程程序设计笔记一]]></title>
    <link href="http://studentdeng.github.com/blog/2010/04/16/mult-threading/"/>
    <updated>2010-04-16T18:11:00+08:00</updated>
    <id>http://studentdeng.github.com/blog/2010/04/16/mult-threading</id>
    <content type="html"><![CDATA[<p>多线程编程，学习了一个星期，总结一下。以下内容全部基于windows操作系统。  由于实力有限，对操作系统没有深入了解（或是根本不了解吧），一下内容主要来自《windows核心编程》、《win32多线程程序设计》、一些网上高人的见解和自己的理解而自己的认识难免有些偏差，希望大家挑挑毛病。谢谢。</p>

<h1>进程和线程的区别。</h1>

<p>进程通常被定义为一个正在运行的程序实例，它由两个部分组成</p>

<p>1.操作系统用来管理进程的内核对象。内核对象也是系统用来存放关于进程的统计信息的地方。
2.地址空间，它饱含所有可执行模块或DLL模块的代码和数据。它还包含动态内存分配的空间。如线程堆栈和堆分配空间。</p>

<p>线程是CPU调度的基本单位。由两个部分组成的</p>

<ol>
<li>一个是线程的内核对象，操作系统用它来对线程实施管理。内核对象是系统用来存放线程统计信息的地方。</li>
<li>线程堆栈，它用于维护线程在执行代码时需要的所有函数参数和局部变量。</li>
</ol>


<p>单个进程可能包含多个线程，而线程都“同时”执行进程地址空间中的代码，为此每个线程都有它自己的一组CPU寄存器（称为线程的上下文）和它自己的堆栈。进程是不活泼的，从不执行任何东西，它只是线程的容器。操作系统为每个线程安排一定的CPU时间片，仿佛所有线程都是同时运行一样。在同一个进程下的多个线程，能够执行相同的代码，对相同的数据进行操作，共享内核对象句柄。</p>

<h1>Context Switch</h1>

<p>在一个抢占式多任务操作系统中，操作系统确保每个线程都有机会执行，它依赖硬件的协助以及其他的工作。当硬件计时器认为某个线程已经执行够久了，就会发出一个中断，与之CPU保存线程的当前状态，把所有寄存器内容复制到堆栈中，再把它从堆栈中复制到CONTEXT结构中。操作系统通过恢复CONTEXT结构中的寄存器值来切换不同的线程。（当然得先切换到该线程隶属的进程内存）。这个过程为Context Switch 。当然如果有非常多的CPU，也就不需要进行Context Switch。</p>

<h1>使用多线程的原因。</h1>

<ol>
<li>和进程相比，它是一种非常"节俭"的操作方式。启动一个线程所花费的空间远远小于启动一个进程所花费的空间，而且，线程间彼此切换所需的时间也远远小于进程间切换所需要的时间。</li>
<li>线程间方便的通信机制。同一进程下的线程之间共享数据空间，所以一个线程的数据可以直接为其它线程所用。</li>
<li>提高应用程序响应。这对图形界面的程序尤其有意义，当一个操作耗时很长时，整个系统都会等待这个操作，此时程序不会响应键盘、鼠标、菜单的操作，而使用多线程技术，将耗时长的操作和UI线程工作分开。</li>
<li>线程彼此分享了大部分核心对象的拥有权。</li>
<li>在多CPU下，多个线程可以真正的同时运行，提高了CPU的利用率。</li>
</ol>


<h1>多线程所带来的问题</h1>

<ol>
<li>多线程在单CPU上实际上是一个假象，CPU的时间总是有限的，如果用的不好，反而增加了CPU的负担，降低了系统性能。</li>
<li>多线程发生共享数据空间，在这个抢占式环境下线程运行次序无法预期，容易产生竞争，导致程序效率降低，出错，甚至死锁。</li>
<li>过多的线程导致过多的Context Switch，也会降低运行效率。</li>
</ol>


<p>讲了这么多，可见多线程程序设计给程序员带来了更高的要求。再查MSDN的时候，有的API会附上线程安全而有的却没有。下面我们开始进入多线程编程世界。</p>

<p>在进入多线程世界之前，先想一个问题。</p>

<p>设想一下，假如有一个简单的增添链表的操作</p>

<pre><code>AddHead(struct List *list,struct Node *node)
{
   node -&gt; next = List-&gt;head;
   List-&gt;head = node;
}
</code></pre>

<p>这个程序若是在多线程下进行的话，会出问题。 比如当thread1 正在执行 AddHead，而Context Switch发生在node->next = List->head 和 List->head = node语句之间，而thread2也要执行AddHead，而且正确执行之后，并把一个节点添加到List中，那么当Context Switch发生，而thread1执行List->head = node后，那么thread2添加的节点就不在List中了，造成了内存泄露，而且的确，你可以想到很多出错的可能性。你可能说这个问题出现的概率很低，但是多想一下，若是这个程序是在一个搜索引擎中，每天有多少人去运行这个程序？而且CPU是以每秒千万级（我的YY，反正是很快）运行，那么程序的问题就不可避免。而之所以产生了问题，就是因为thread1和thread2产生了竞争（race condition）。</p>

<p>当然可能你一下子就有了思路，产生这个问题的关键是在于在发生race 的地方设置变量，来“保护”AddHead的操作正确。</p>

<pre><code>AddHead(struct List *list,struct Node *node)
{
   while(flag !=0)
   flag = 1;
   node -&gt; next = List-&gt;head;
   List-&gt;head = node;
   flag = 0;
}
</code></pre>

<p>这个代码似乎可以正确运行，但是很遗憾，还是不行。好吧让我们先来明确一个知识。<strong>Atomic Operations(原子操作)</strong>。
一下是AddHead的汇编代码</p>

<pre><code>AddHead(struct List *list,struct Node *node)
{
  xor eax,eax 
  s: 
  ;while(flag !=0) 
  cmp DWORD PTR _flag,eax 7   
  jne short s 
  ;flag = 1; 
  mov eax,DWORD PTR _list$[esp-4]
  mov ecx,DWORD PTR _node$[esp-4]
  mov DWORD PTR _flag,1
  ;node -&gt; next = List-&gt;head;
  mov edx,DWORD PTR [eax]
  mov DWORD PTR [ecx],edxx
  ;List-&gt;head = node;
  mov DWORD PTR [eax],ecx
  ;flag = 0;
  mov DWORD PTR _flag,0
  ret 0
   ;小弟还没学习完汇编，有一些操作码还是不知道，只能是理解意思，不能保证
  ;肯定能执行，例子来自《Win32多线程程序设计》
;}

# Atomic Operations(原子操作)

简单的几行代码在执行时会转换成这么多代码，不能指望C，C++这种高级语言的语句可以一次执行完毕而不发生Context Switch。
</code></pre>

<p>而且还存在编译器优化（比如一些循环语句等等）真实在机器上执行的代码可能和你所希望的是不同的。</p>

<p>原子操作（Atomic Operation ）指一个操作如果能够不受中断的完成。</p>

<p>所以上例的检查标记和设立标记的动作必须是一个Atomic Operation，如果中断了，就不能避免竞争。</p>

<p>好吧让我们真正的开始多线程编程旅行吧，我们和学习其他任何知识一样，来一个HelloWorld。</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;windows.h&gt;

DWORD WINAPI ThreadFunc(LPVOID);

int main()
{
    HANDLE hThrd;
    DWORD threadId;
    hThrd = CreateThread(NULL,
,
            ThreadFunc,
,//(LPVOID)i,
,
            &amp;threadId );
    if (hThrd)
    {
      printf("Thread launched\n");
      CloseHandle(hThrd);
    }
    //Sleep(2000);
    return 0;
}

DWORD WINAPI ThreadFunc(LPVOID n)
{
  printf("HelloWorld\n");
  return 0;
}
</code></pre>

<p>运行后发现悲剧了,Thread launched有了,但是没有我们的熟悉HelloWorld(对大部分人来说是没机会看到HelloWorld的),那么我们又遇到什么问题了?</p>

<p>加上Sleep后,HelloWorld出现了,好吧,我们又发现了,创建一个线程,并写一个调用函数,和我们在main函数中写一个子程序不是一回事。</p>

<p>一个函数调用操作，程序的控制权转移到被调函数中，执行完毕后在返回原调用处。</p>

<p>产生一个线程，情况也十分类似，但是有些曲折，线程函数中我们是通过CreateThread，并传给ThreadFunc的地址。CreateThread开启一个新的线程，该线程调用ThreadFunc而原来的线程继续前进。好吧。ThreadFunc相对main来说异步执行了。那么ThreadFunc不需要在main结束之前返回，所以，main函数返回了，ThreadFunc还没来得及返回，所以没有显示HelloWorld，而Sleep之后，那么ThreadFunc返回了，那么也就显示HelloWorld。</p>

<p>当main函数返回后，操作系统中止整个进程，收回大部分或全部资源，而你的thread就还没工作完就被“干”掉了。</p>

<p><strong>当然你也可能会产生另一个疑问，main函数返回了，进程结束了，thread就直接悲剧了，能不能让main函数返回，进程不结束，thread不悲剧呢？</strong></p>

<pre><code> static void Main(string[] args)
 {
   Thread th = new Thread(ShowWindow);
   th.Start();
   Console.WriteLine("窗体已创建,敲任意键退出...");
   Console.ReadKey();
   Console.WriteLine("Main thread End");
 }
  static void ShowWindow()
 {
   MessageBox.Show("test");
 }
</code></pre>

<p>这是一段C#代码，主要来自<a href="http://blog.csdn.net/bitfan/archive/2010/01/14/5191299.aspx">ref</a>我稍微改动了一点点，这段代码可以保证即使主线程退出了，只要窗体没有关闭，操作系统会认为“进程”仍在执行，因此，控制台窗口会保持显示，直到窗体关闭，整个进程才结束。在这种情况下，本示例程序中有两个UI线程，一个是控制台窗口，另一个创建应用程序窗体的那个线程。</p>

<p>如下是我模仿上边代码，写的c++的例子</p>

<pre><code> int main()
 {
   HANDLE hThrd;
   DWORD threadId;
   HANDLE handle;
   hThrd = CreateThread(NULL,
           0,
           ThreadFunc,
           0,//(LPVOID)i,
            0,
           &amp;threadId );
   if(hThrd)
   {
     printf("Thread launched\n");
     CloseHandle(hThrd);
   }
   Sleep(5000);
   printf("Main Thread End\n");
   return 0;
 }
 DWORD WINAPI ThreadFunc(LPVOID n)
 {
   MessageBox(NULL,"test","test",MB_OK);
   printf("thread1 End\n");
   return 0;
 }
</code></pre>

<p>令人遗憾的是，我写的这个，在main函数返回后，整个进程也随之结束了。。。。。。</p>

<p>好吧。我承认我错了，到底哪里出了问题。我是搞不定了。这个花了我大概2天的时间，曾经我一度以为UI线程和Message queue之间有某种必然的联系，但是上例完全证明了我之前的想法是可笑的或是我整个思考出发点就是错误的。在thread1中不仅调用了GDI函数，而且能够响应消息（说明已经有了Message queue和Message loop）。</p>

<p>看来我得继续学习才能搞定这个了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[缩略图设计初探二]]></title>
    <link href="http://studentdeng.github.com/blog/2010/04/06/thumb-pic2/"/>
    <updated>2010-04-06T18:43:00+08:00</updated>
    <id>http://studentdeng.github.com/blog/2010/04/06/thumb-pic2</id>
    <content type="html"><![CDATA[<p>之前的问题还是很大的，参考了.net framework Dictionary的思路，保留MPQ的hash算法和判断冲突的思路。重新整理了一下。</p>

<p>第一部分：改进部分</p>

<p>1、处理冲突的方法由原来线性再散列，改为分离链表法。</p>

<p>2、修正了一些因为处理冲突而变化的部分。</p>

<p>3、增加了扩容的部分。</p>

<p>4、增加了CRC校验部分。</p>

<p>第二部分：疑问</p>

<p>1、如何保证数据的安全性？Delete操作只是将数据从hashTable中delete，但是文件中依然有图片存在。</p>

<p>要么将每个图片加密储存，但是手机上资源消耗太大。那么最有可能就是delete之后将文件数据格式中关键数据上写一些随机数，从而正常解码失败。</p>

<p>2、如果要统一管理图片，需要建立文件索引。</p>

<p>3、过多的seek会影响效率，我这里还是保存了文件的偏移量，在读取的时候也必然会seek，因为我觉得使用seek似乎没有在效率产生很大的损失（可能我测试的数据不具有普遍性吧），但是很多资料上都对寻道很讨厌。这里我又参考了一下空间问题，故而保存了文件偏移量。</p>

<p>第三部分：部分代码</p>

<p>插入</p>

<pre><code>BOOL MPFile::InsertData( LPCVOID lpBuffer, TCHAR *lpszString, const UINT fileSize, const FILETIME LastModiTime, 
        LONG &amp;lindex, DWORD dwFlags )
{
    ASSERT( lpBuffer != NULL );
    ASSERT( lpszString != NULL );

    if( m_pMPBlockTable == NULL ) Initialize(0);
    const DWORD HASH_OFFSET = 0, HASH_A = 1, HASH_B = 2;   
    DWORD hashCode = hash.HashString(lpszString, HASH_OFFSET);   
    DWORD nHashA = hash.HashString(lpszString, HASH_A);   
    DWORD nHashB = hash.HashString(lpszString, HASH_B);   

    DWORD targetBucket = hashCode % (m_pMPFileHeader-&gt;nHashTableLength); 
    for ( LONG i = m_pMPBlucketTable[targetBucket].iBlockIndex; i &gt;= 0; i = m_pMPBlockTable[i].MPEntry.iNext ) 
    {
        if( m_pMPBlockTable[i].MPEntry.dwHashCode == hashCode
    　　　　&amp;&amp;m_pMPBlockTable[i].MPEntry.dwHashValueA == nHashA 
    　　　　&amp;&amp; m_pMPBlockTable[i].MPEntry.dwHashValueB == nHashB )
        {
        if( !(dwFlags &amp; INSERT_REPLACE_EXISTING) ) {return FALSE;}
            return SetDataToFile(lpBuffer,lpszString,i);
        }
    }
    // add new 
    LONG index;
    BOOL isNew=TRUE;
    if (m_pMPFileHeader-&gt;nFreeCount &gt; 0) 
    { 
        index = m_pMPFileHeader-&gt;iFreeList;
        m_pMPFileHeader-&gt;iFreeList = m_pMPBlockTable[index].MPEntry.iNext;
        m_pMPFileHeader-&gt;nFreeCount--;
        isNew = FALSE;
    } 
    else 
    {
        if (m_pMPFileHeader-&gt;nChildFileCount == m_pMPFileHeader-&gt;nHashTableLength) 
        {
            ReSize();
            targetBucket = hashCode % (m_pMPFileHeader-&gt;nHashTableLength);
        }
        index = m_pMPFileHeader-&gt;nChildFileCount;
        m_pMPFileHeader-&gt;nChildFileCount++;
    } 

    m_pMPBlockTable[index].MPEntry.dwHashCode= hashCode; 
    m_pMPBlockTable[index].MPEntry.iNext = m_pMPBlucketTable[targetBucket].iBlockIndex; 
    m_pMPBlockTable[index].MPEntry.dwHashValueA = nHashA;
    m_pMPBlockTable[index].MPEntry.dwHashValueB = nHashB;
    m_pMPBlockTable[index].dwFlag = dwFlags;
    m_pMPBlockTable[index].nSize = fileSize + sizeof(MINIPICDATAITEMHEADER)+sizeof(DWORD);//size add fileName and crc32
    m_pMPBlucketTable[targetBucket].iBlockIndex = index;

    lindex = index;

    //TODO:修改数据
     if(isNew)
    {
        m_pMPBlockTable[index].FileStartAt = m_endOfFileData;
        if(SetDataToFile(lpBuffer,lpszString,index) )
        {
            m_endOfFileData+=m_pMPBlockTable[index].nSize;//TODO:防止溢出
        　　  return TRUE;
        }
        return FALSE;
    }
    else
    {
        return SetDataToFile( lpBuffer,lpszString, index );
    }
}
</code></pre>

<p>读取数据</p>

<pre><code>LONG MPFile::FindEntry( TCHAR *lpszString )
{
    ASSERT(lpszString!=NULL);
     if (m_pMPBlucketTable != NULL ) 
     {
        const DWORD HASH_OFFSET = 0, HASH_A = 1, HASH_B = 2;   
        DWORD    hashCode = hash.HashString(lpszString, HASH_OFFSET);   
        DWORD    nHashA = hash.HashString(lpszString, HASH_A);   
        DWORD    nHashB = hash.HashString(lpszString, HASH_B);   
        DWORD    nHashStart = hashCode % (m_pMPFileHeader-&gt;nHashTableLength);   

        for (LONG i = m_pMPBlucketTable[nHashStart].iBlockIndex; i &gt;= 0; i = m_pMPBlockTable[i].MPEntry.iNext) 
        {
            if (m_pMPBlockTable[i].MPEntry.dwHashCode == hashCode 
                &amp;&amp;m_pMPBlockTable[i].MPEntry.dwHashValueA == nHashA 
                &amp;&amp; m_pMPBlockTable[i].MPEntry.dwHashValueB == nHashB )
            return i;
        }
     }
     return -1;
}
</code></pre>

<p><a href="http://files.cnblogs.com/studentdeng/MP_v2.rar">MP_v2.rar源码</a></p>
]]></content>
  </entry>
  
</feed>
