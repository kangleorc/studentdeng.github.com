<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: operating_system | 不会开机的男孩]]></title>
  <link href="http://studentdeng.github.com/blog/categories/operating-system/atom.xml" rel="self"/>
  <link href="http://studentdeng.github.com/"/>
  <updated>2013-08-08T12:26:56+08:00</updated>
  <id>http://studentdeng.github.com/</id>
  <author>
    <name><![CDATA[studentdeng]]></name>
    <email><![CDATA[studentdeng@hotmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Orange‘s 一个操作系统的实现 配置问题]]></title>
    <link href="http://studentdeng.github.com/blog/2012/02/16/selfos/"/>
    <updated>2012-02-16T23:57:00+08:00</updated>
    <id>http://studentdeng.github.com/blog/2012/02/16/selfos</id>
    <content type="html"><![CDATA[<p>最近在瞅《Orange‘s 一个操作系统的实现》，个人认为相当好的OS入门实践书籍，配合之前看过的大部分的理论书，容易理解那些抽象的概念（无代码无真相），</p>

<p>和《Linux内核完全注释》都是相当不错的入门书籍。</p>

<p>这里记录一下可能遇到的问题，主要是配置问题，实现逻辑书里面很详细，代码注释也很详细，仔细多想应该没啥问题。</p>

<p>我这里环境是ubuntu 10 64bit， 而书中代码是32bit的。这里在编译链接的时候出了一点小问题。这里记录下。</p>

<p>错误：</p>

<pre><code>ld: i386 architecture of input file `kernel/kernel.o' is incompatible with i386:x86-64 output
</code></pre>

<p>需要修改makefile</p>

<pre><code>CFLAGS          = -I include/ -c -fno-builtin -m32
LDFLAGS         = -m elf_i386 -s -Ttext $(ENTRYPOINT)
</code></pre>

<p>错误：</p>

<pre><code>klib.c:(.text+0xe5): undefined reference to `__stack_chk_fail'
</code></pre>

<p> 这里应该是少了c的标准库，还是需要修改makefile文件</p>

<pre><code>LDFLAGS         = -m elf_i386 -s -Ttext $(ENTRYPOINT) -lc
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[胡言乱语计算机二]]></title>
    <link href="http://studentdeng.github.com/blog/2011/02/27/computer2/"/>
    <updated>2011-02-27T23:08:00+08:00</updated>
    <id>http://studentdeng.github.com/blog/2011/02/27/computer2</id>
    <content type="html"><![CDATA[<p>中断和异常处理是OS中非常重要的组成部分，当然windows也不例外，他们是我们理解OS一些概念、机制的基础。</p>

<p>中断和异常简单的来说，就是在程序正常执行流程中，突发一个事件，导致程序的执行流程转向另外的执行流程中。而我们绝大多数编写的程序都是顺序执行的，我们的确体会不到这样的机制能够给我们带来多少好处。但是这个在OS的设计中，确实深入到各个方面，以至于没有中断异常处理，现代OS根本无法构建。为了简单理解，我们可以看看这个例子。</p>

<p>比如我们准备带我们的宠物狗狗出去散步，但是由于狗狗非常淘气，经常单独行动（这里，我们是无法预知狗狗会在什么时候跑掉的），在没有任何其他道具的帮助下，我们只能每隔一段时间去看看狗狗是否跟着我们。那么用code来模仿这个行为，那么就是这个样子。</p>

<pre><code>while(living) //人的行为简单说其实就是不断的重复重复...
{
    //do something
    ...
    if(!VerifyDog())//看看狗狗还跟的没有
    {
        //狗丢了....    
    }
    ...    
}
</code></pre>

<p>如果我们这个while循环中，没有其他事情，仅仅是和狗狗在一起，那么狗狗不会丢，但是如果我们突然遇到一个美女，驻足观赏了一会之后…狗狗不见了。</p>

<p>是的，我们通过轮询这种方式，不可能保证狗狗一定会在我们身边。那么如何才能保证狗狗一定在我们身边呢？无论我们走到哪里都会紧紧跟着呢？生活常识告诉我们，只需要给狗狗戴上链子，这样狗狗就会“听话”的跟在我们左右。那么我们就可以通过这样的code来展示我们的行为。</p>

<pre><code>while(living)
{
    leash(FuncProc); 
    while(bOutSide)
    {
       //doSomeThing 
    }
    UnLeash();    
}

FuncProc()
{
    狗狗想跑,抓紧链子。：）
}
</code></pre>

<p>好了，在我们带狗狗出去玩之前，我们给狗狗栓了链子，那么我们在外出的时候，就可以随行所欲的“看美女了”。一旦狗狗有不轨行为，我们只是需要下意识的抓紧便能保证狗狗不会跑丢。而这，要比隔一段时间查看狗狗在不在要简单多了，我们可以完全从这个事情上解脱出来。做更重要的事情。而这一切，其实就是默默跑了一个异常处理的过程。</p>

<p>我们通过leash(FuncProc); 注册了一个callback函数
我们可以做我们想做的事情，而不在我们的while循环中体现任何有关狗狗的信息。
当狗狗有不轨行为时，链子第一时间通知我们狗狗的行为，然后我们能够在第一时间制止狗狗。
然后我们继续while中的事情。
当然，回家了要把狗狗放出来（大部分的狗狗都不喜欢狗链子….）。
从某种角度上来看，OS相当于人，而我们写的一些应用层的程序则相当于宠物狗狗。而异常处理，就是这条链子。对操作系统来说，他希望找到一条能够应对所有狗狗的超级链子。而在这么多狗狗中，总有那些不听话的，希望能够摆脱这条链子的狗狗。而这条链子也在这2端的发展下，变得越来越强壮。</p>

<p>这篇文章的角度就是站在OS的角度，希望找到这条能够应对各种狗狗（主要是不听话的狗狗）的链子。也就是初步学习windows 的SEH的整体设计和思路（这个帽子的确很大）。下一篇则站在狗狗的角度来学习我们如何能够摆脱这条链子（这个帽子也挺大的），也就是SEH的相关安全机制。当然这篇是理解后面的基础。</p>

<p>当然，OS本身的实现和人狗链子的关系也是微妙的。现代操作系统的整个设计是分层的。有些时候是人是狗已经不再重要了。就像真实世界的我们，我们无法从那些枷锁中挣脱，真的。我们有时候真不知道我们是人？是狗？</p>

<p>闲话扯得太多了。为了更清楚的了解异常，我们需要进一步了解我们的计算机。类似的这种程序控制流的变化，还有中断(interrupt)，陷阱(trap)，错误(fault)，终止（abort）而中断，我们通常又分为软中断，和硬中断（这个又通常省略硬字）。是的，我相信对于绝大多数的和我一个水平的菜鸟来说，这些概念都是可以令人抓狂的。而造成这样的原因主要是在于计算机的发展是在是太快速了，所以，有些概念在这个过程中得到了扩展，而这些概念又和计算机体系结构密切相关，所以我们经常看到甚至是一些权威书籍之间有概念的冲突，是的。这个当然不是人家的错误，只是处在了不同的时空，而这也就是语言的悲剧。他永远不可能给我们准确的答案，除非数学。所以这里我们需要先搞清楚这些概念。把那些恼人的语言上的细枝末节过滤掉之后，整个东东也不复杂了。当然整个学习都在我们最“熟悉”的x86下，其他平台也不不难掌握了。</p>

<p>为了减少中英文的差异，在一些概念描述上，这里就不再一次引入另一门语言，虽然他是伟大的语言。为了能够较为清晰的了解他们之间的区别。我们不得不扯一些硬件相关的知识，事实上，也许这些“旁敲侧击”让你回想到了学校的那些认为不重要的课程《机组》《模电》《计算机体系结构》《微机原理接口》等。</p>

<p>在8086下，原谅我再次重复，有2种这样的机制。interrupt、exception。interrupt分为可屏蔽中断和不可屏蔽中断。exception分为 fault、trap、abort。概念有点多，慢慢来。</p>

<p>经过上一篇的胡扯，我们知道了CPU眼中，把这些硬件当成逻辑存储器，最后和存储器构成一个地址空间。但是有些笼统，这里稍微再了解一点。和CPU通过总线相连的芯片除了各种存储器外，还有3种芯片</p>

<ul>
<li>各种接口卡（显卡，网卡）上的接口芯片，它们控制接口卡</li>
<li>主板上的接口芯片，CPU通过它们对一些外设访问</li>
<li>其他芯片，存储相关的系统信息或对输入输出处理</li>
</ul>


<p>而这些芯片都有一组可以由CPU读写的寄存器。这些寄存器有2点相同。</p>

<ul>
<li>和CPU总线相连。</li>
<li>CPU对它们进行读写是通过控制些向他们所在的芯片发出端口读写命令</li>
</ul>


<p>所以，在CPU看来，这些外部的寄存器相当于端口，并对他们一起编址，从而又搞了一个端口地址空间，或是叫做IO端口空间。这里再扯的远一点，事实上，在x86下，我们现在知道有2个地址空间，一个是存储器的地址空间还有一个是IO地址空间，为什么不把IO地址空间也映射到存储器地址空间中呢？这样我们就可以再弄一些逻辑存储器了。是的这样设计的确简单，但是却浪费了一些CPU的地址空间，所以当时intel考虑到为了不浪费而又搞了一个IO地址空间，所以我们访问这些端口的时候，也就必须通过另外的指令来做。我们把这种IO编址称为独立编址。x86一共有64K个8bit的IO端口。事实上还有另一种思路和我们之前的想法一致，将这些IO的空间跑到了存储器地址空间，而这个又叫做统一编址。也就是说，这些IO寄存器与存储器单元一样看待。这样的设计在ARM中则比较常见。呵呵，有点乱，让我们看个例子。</p>

<p>那就用我们最熟悉的键盘来说。当我们在键盘上操作时，CPU是如何知道的呢？</p>

<p>键盘中有专门的芯片用于监视键盘上每一个键的状态，当我们按下一个键时，接通电路，这个芯片就会产生一个成为扫描码的东东，来表示键的位置，当键弹起的时候，同样产生一个扫描码。扫描码就保存在了键盘接口芯片的寄存器中（CPU来看这就是一个端口）。那么当键盘的输入到到端口时，我们这篇文章的主角终于来了。芯片向CPU发出中断信息。到这里，键盘的事情OK了。</p>

<p>那么芯片是如何给CPU发送中断呢？我们可以通过线将CPU和芯片连接起来，但是这样会遇到一个无法回避的问题，可以和CPU连接的线是有限的，但是CPU外部的这些设备确是非常多的，所以必须管理这些设备，让其中一些设备共享一条线。而这也就是中断控制器的作用之一，所以，真实的情况是类似如下的。</p>

<p><img src="/images/computer2.png" alt="alt text" /></p>

<p>inter x86通过2片中断控制器8259A来响应外部中断源（就是指产生中断的设备，比如键盘）。和中断控制器相连的每条线被称为中断线。我们看出如果想发送中断给CPU，那么必须得获得这条线的控制权。那么我们申请中断线的这个动作，叫做IRQ（Interrupt ReQuirement）。当然“申请中断线”这也有一个更加专业的叫法申请IRQ或是申请中断号。</p>

<p>而这个8259A做的事情就是</p>

<ul>
<li>监视中断线，检查产生的IRQ信号</li>
<li><p>如果中断线上产生了一个IRQ信号</p>

<p>  把IRQ信号转换成对应的中断向量
  这个向量存放在中断控制器的一个IO端口，CPU从而可以通过数据总线访问向量
  这个信号则发送到CPU的INTR引脚，也即是触发一个中断
  等待CPU确认中断之后，写入PIC(可编程中断控制器)的IO端口，并清INTR</p></li>
</ul>


<p>但是事实上还没有完，我们知道CPU在一个时刻只能处理一个事情。我们有那么多的外围设备，当他们都要CPU时间时，这里就有一个先后问题了。也就是需要对这些中断分级别。而且在有些特殊的中断下，是不可以被其他中断打断的。呵呵，这里就引入了可屏蔽中断和不可屏蔽中断。那么我们就可以有选择的处理一些中断，而放弃另一些中断在一些极端情况下。而且有些中断处理过程中是不可以再处理中断的。可屏蔽中断IRQ信号通常是通过CPU的INTR引脚发给CPU的。而不可屏蔽中断信号通常是通过NMI引脚发给CPU。呵呵，这就是可屏蔽中断和不可屏蔽中断区别之一。</p>

<p>那么我们再来搞定异常。</p>

<p>为了能够稍微再了解一点，我们需要知道一些CPU内部是如何执行一条指令的。原谅我这里就不赘述了。只是搞一个例子。</p>

<p>当CPU执行汇编指令IDIV。首先会检查源操作数（除数）是否为0，如果为0，则CPU在执行这条指令中，就会产生一个除零异常（在CPU眼里，汇编也成高级语言了）。通过中断的例子，我们看出，中断是CPU外部告诉CPU的执行流程需要转变。那么异常和中断最大的不同就是异常是CPU自己本身执行时发现的。中断的来源通常是外部设备，异常的来源则有3种。</p>

<ul>
<li>程序错误，当CPU在执行程序指令时遇到操作数错误或是指令非法。前者的例子就是除零，后者的例子可以是在用户模式下执行特权指令</li>
<li>某些特殊指令。这些指令的本身就是产生异常。</li>
<li>intel在P6引入了机器检查异常（Machine Check Exception）。当CPU执行指令期间检测到CPU内部或是外部硬件错误。</li>
</ul>


<p>可见，对CPU来说，中断是异步的，因为CPU完全是被动的指望外部硬件给他一个信号。而异常，则是CPU自己发起，从CPU来看则是同步的。</p>

<p>我们之前已经了解了CPU是如何获知异常，中断。那么CPU接下来的动作又是什么呢？首先需要区分出这些不同的异常，中断。具体则是需要区分出产生中断的来源，8086使用被称为中断类型码的数据来表示中断源。中断类型码为一个字节数据。8086最多可以表示256种中断源。那么接受到各种中断或是异常时，接下来需要做不同处理，那么分别处理中断或是异常的程序入口，叫做中断向量（这里可没有异常向量一回事，这里被统一看待）。而这些中断向量组成一张线性表被称为中断向量表。由于是线性表，我们可以很容易的构造一个类型码到中断向量的映射。</p>

<p>这里还需要强调一点。之前我们提到的异常的分类，那么这些异常的区别是什么呢？既然是控制流的转变，那么就有如何恢复和如何报告控制流转变这2种情况需要我们考虑，而事实上，fault abort trap 就是按照这样划分的。</p>

<ul>
<li>错误类（fault）异常是在产生这个异常指令的指令之前发起。fault通常在执行指令或是执行指令之中被CPU检测到。如果检测到，那么异常将机器的状态恢复到这条指令开始的地方，这样。指令就可以继续执行。可见错误类异常可以无缝继续执行，但是如果没有解决，则会陷入死循环。</li>
<li>陷阱（trap）异常是在产生这个异常指令完成之后，立即产生。那么异常之后的恢复就是引起这条指令的下一个指令（这个是逻辑上的，可不是空间上的）。 可见trap也是可以无缝继续执行。</li>
<li>终止（abort）异常用来报告严重的错误，而这种错误已经严重到不可恢复的地步，也可以说，我们已经不知道该如何恢复了。整个都乱了。比如一些硬件错误。</li>
</ul>


<p>当然到了80386之后，由于保护模式的引入，这部分又引入了各种门，中断们，陷阱门等等，恢复的过程也分了内核态和用户态。而这些个过程，绝大多数书籍都有相关详细的说明，这里不做赘述。有兴趣的同学可以自己翻阅。这里引入这些概念是为了对硬件处理中断有一个笼统的概念，这样会对我们理解OS是如何模拟这个异常过程提供一些帮助。</p>

<p>这里还需要再强调一点，我们可以通过一些指令来屏蔽 可屏蔽中断，事实上，大多数的外接设备都是可屏蔽中断。但是我们的异常确是不可以被屏蔽的。有了之前的基础，我们可以从硬件本身的搭建思考这个原因，也可以从整体设计去思考这样设计的原因。这里算是留个问题吧。我已经觉得我是在是太罗嗦了。</p>

<p>当然这些划分也不是非常精确，有一些错误类异常也是不能恢复执行的。哎，没办法，谁让这计算机是人造的呢。事实上，计算机的世界中充斥着“差不多”，“懒惰”这类思想，如果非要钻严谨的牛角尖只会增加自己的痛苦。因为我们不是在搞数学，有些东西可能背负着我们现在的视野所不能企及的历史问题。所以还是那句话，存在即是道理。我们没有资格对他们评头论足，在我们彻底搞出一个自认为更加合理的东西之前。当然这也是人造科学最让一些喜欢追求完美的家伙们郁闷的地方。呵呵，如果真的有可能，真的应该去拥抱数学。当然人造科学也有好处，是的。他和我们大多数的思维一致，甚至是我们现实经验的抽象，看看计算机的那些最基本的核心概念，stack queue。</p>

<p>差点忘了，还有一个软中断的概念，这里通常指的是INT n这样的指令。如果站在CPU的角度，这个明显是异常，因为这个控制流的转变是CPU内部检测到的。</p>

<p>让我们从茫茫的硬件跳出来。别忘了我们是要了解OS的异常处理。我们可对CPU的世界没有兴趣。是的。正是因为这些硬件太过于底层，而且不同的硬件结构都有不同的地方。那么操作系统如何来保证自己可以在多个这样的硬件平台上执行呢？一个最常见，最通俗的就是OS自己再抽象一个异常，中断。自己定义一个。是的，再没有比自己推倒旧体制，重建新秩序让人更兴奋的了。这样上层的应用就不需要考虑这些细枝末节了。事实上，OS是将这些异常，中断打包在一起管理的。因为他们本质上都是程序执行流程的转换。我们只能看到这是一种“跳转，恢复”而已。所以，现在我们可以忽略掉上面所讲的所有东西。（这里可能会有一种误解，所以我这里叫胡言乱语，要想完全真实的了解这些过程，intel手册，当然如果想要吃下这东西，《机组》《体系结构》….）。</p>

<p>庄子也讲，计人之所知，不若其所不知；其生之时，不若未生之时；以其至小求穷其至大之域，是故迷乱而不能自得也。这些东西还是因人而异。我这里可没有给大家传递必须要学那些硬件知识，或是鼓励大家怎么怎么做。事实上我也没有这个能力，退一步，即使我有这个能力，也没有这个资格。用自己的特例来推广到大家这本身就是一个本末倒置的问题。其实，哎，再加一句废话。存在即是理由，技术本身没有错，错的只是人的角度而已。而这也就是人造科学的悲剧，它不可能让所有人都满意，相反那些只有神才能理解的东西--数学，不以人类意志为转移。</p>

<p>让我们扯开那些鸡毛蒜皮的东西，静下心来。站在OS的角度来观察异常。那就拿我们最“熟悉”的windows。好吧。windows自己搞了一个异常处理机制。而这里面最熟悉的就是SEH了。当然这不是windows中唯一的异常处理机制。等我们了解SEH之后，再了解他。因为他并不是NT设计之初就存在的。这里可能又要绕绕了。MS真正的操作系统是NT。而95 98 只是dos的一层皮，并不真正算我们想象中的操作系统。</p>

<p>当然NT也搞了自己的一套中断的概念，只是这里。我觉得我们应该暂时放下。在OS，IO处理那部分在来讲述。我觉得这次的硬件有些多了。涉及的太多，反而不能讲述清楚了。</p>

<p>既然我们要弄一个抽象的中间值，那么我们显然只能从异常被CPU识别，然后经过各种机制之后，扔给我们来看的就是NT给我们定义的异常，也是给他自己定义的异常。</p>

<pre><code>typedef struct _EXCEPTION_RECORD { 
    DWORD ExceptionCode; 
    DWORD ExceptionFlags; 
    struct _EXCEPTION_RECORD *ExceptionRecord; 
    PVOID ExceptionAddress; 
    DWORD NumberParameters; 
    DWORD ExceptionInformation[EXCEPTION_MAXIMUM_PARAMETERS]; 
}  EXCEPTION_RECORD;
</code></pre>

<p>EXCEPTION_RECORD 定义异常，更多的可以参考msdn，http://msdn.microsoft.com/en-us/library/aa363082(VS.85).aspx这里只是简单提几点。</p>

<p>ExceptionCode 是NT分配给异常的编码，用来表示是一个什么样的异常。比如我们最熟悉的 0xC0000005 STATUS_ACCESS_VIOLATION。</p>

<p>ExceptionAddress 则表示异常产生的地方。（这里其实是不准确的，如果我们从硬件的角度去看，因为有些地方windows替我们做了一些额外的事情。后面会提到一个例子。）</p>

<p>既然要模拟实现这种程序控制流的转换，那么我们需要提供系统一个函数执行的入口，说白了就是一个函数指针。那么就是下面的这个样子。</p>

<pre><code>EXCEPTION_DISPOSITION 
__cdecl _except_handler( 
     struct _EXCEPTION_RECORD *ExceptionRecord, 
     void * EstablisherFrame, 
     struct _CONTEXT *ContextRecord, 
     void * DispatcherContext 
     );
</code></pre>

<p>让我们先略过这些参数。思考一些问题。我们应该如何注册我们的函数入口，何时解除我们的回调函数。如果站在NT的角度，这些函数入口又该记录在哪里？</p>

<p>最直观的想法就是模仿硬件那种线性设计，搞一张表，来存储这些函数入口。但是我们这种直接想到的，往往都不是真实的设计。我这里只能猜想，由于这些设计都是20年前的东西，过多的访问外部的表，可能会冲击缓存性能。</p>

<p>那么我们怎么做才能在少影响缓存性能的情况下，还能触发程序执行流程转换？而且我们并不知道哪里会出现程序流程的转换。而且由于我们需要模拟这个流程，也就是要支持底层中的中断来让我们普通程序捕获的同时，我们还想要扩展，自定义一些异常来抛出，使得程序流程转换。这个的确是一个复杂的问题。事实上，在我们的程序中已经给我们提供了一个实现这个机制的空间。他就是计算机中里程碑的东东，堆栈。</p>

<p>堆栈是什么时候出现的，这个已经不清楚了。但是可以确定的是现在已经几乎没有能够脱离堆栈而运行的程序。堆栈给我们提供了非常出色的环境。</p>

<p>记录子程序调用轨迹，使得嵌套子程序调用成为可能
通过堆栈传递子程序调用参数，从而简化程序设计。因为寄存器的数目很可能是不够用的。
基于堆栈的程序局部变量的概念得以出现，使得模块化程序设计和结构化程序设计成为可能，也最后导致了进程，线程。
程序执行的轨迹和局部变量结合一起成为“脉络”即上下文。这给我们恢复程序执行，跳转程序执行提供了保障，甚至后面的调度。
我猜想，正是因为SEH的设计和堆栈密不可分，所以才叫“结构化异常处理”吧。</p>

<p>回想一开始的那个带狗狗出去玩的例子，栓链子和解开链子，构成了一段受保护的空间。事实上，编译器在给我们构造可以支持SEH的环境时，也是这样的。进入<strong>try block之前，加保护，在当前程序的堆栈空间中构造一些结构，也就是我们的回调函数入口等其他一些必要的结构。而当我们离开</strong>try block 之后，则就像释放普通的临时变量一样释放掉这些结构体。而且堆栈还有其他的好处，由于我们可以根据堆栈去构造类似printf的不定参数的功能，所以，编译器在支持NT的SEH机制时，可以加入其他一些结构，这样比较方便的扩展和优化这些基本的机制，从而提高效率。减少支持异常的开销。而且事实上，对于异常的开销，如果没有触发异常，现代的编译器已经几乎做到零开销，只是当真正的触发异常时，效率会大幅下降。当然。异常提供了非常强大的转换程序流程的能力，而这也是那些病毒，木马最喜欢的事情。更不说这些相关的SEH结构体就构造在程序的堆栈中，这种没有任何保护的地方。所以需要非常多的安全机制协同保护。而这些问题，大概直到vista后win7才基本上做到了完美，或是那些牛人还没有找到漏洞。</p>

<p>所以说，我们自定义的异常，一般都是程序执行流程中的极端情况，万万不能像理解硬件中断那种思想去理解，也就是异常是不能用来控制程序中大多数流程转变。只能用于极端情况，作为最后的手段。当然，这个可能并不是20年前的那些牛人都能想到的。相关的有关SEH编译器级实现可以参考</p>

<p>Matt Pietrek的文章</p>

<p>http://www.microsoft.com/msj/0197/exception/exception.aspx，</p>

<p>还有我自己写的2篇。</p>

<p>http://www.cnblogs.com/studentdeng/archive/2010/12/15/1907232.html</p>

<p>http://www.cnblogs.com/studentdeng/archive/2010/12/21/1912991.html</p>

<p>原谅我把我的文章和Matt Pietrek的放到一起。当然，这些东西都是最最基础的。</p>

<p>但是这篇可不是去学习具体的实现机制，要明白这个，还是需要一定的汇编基础和多一些的耐心，其实，怎么说呢，对于c的反汇编，主要还是靠耐心吧，没有太多的技术（纯个人感觉，我觉得c++的需要更多些技术）。而且如果再稍微了解一点SEH的安全机制，就会发现，我们似乎又回到了最开始的想法。构造一个表来保存这些回调函数的一些信息。呵呵，事物的发展似乎又回到了原点，但是我们的认识却不在一个层面上了。螺旋发展，也增加了我们学习这些古老东东的难度。真的，有时候真不知道为什么自己会处在这个时代。20年前的操作系统还有人敢说能够比较全面地了解。对于现在的千万级，有的linux甚至是亿级代码量来说。呼呼。穷极一生也仅仅皮毛而已，不过对于计算机这种新科学来说，还能搞个皮毛。而物理，数学那就是还没了解就over了。。。。。。</p>

<p>对比之前的硬件结构，我们已经了解了我们自定义的“异常信号”，“异常向量”。那么我们又是如何根据“异常信号”找到这些“异常向量”呢？那么我们就必须要了解NT的异常触发的模型了。当异常跳出来时，NT的顺序是这样的。（准确说异常在用户态下，关于内核态的我们不管他）</p>

<ul>
<li>调试器 first chance</li>
<li>堆栈上的那些回调函数</li>
<li>调试器 second chance</li>
<li>环境子系统
怎么说呢，我觉得这篇真的好长，环境子系统还是放在OS进程线程那部分了解吧。现在可以把它想象成NT进程的妈吧。反正只要是要创建一个进程都要告她一下。当异常最后也没找到属于他的回调函数，那么就给他妈管教了。当然，NT之所以这样设计异常，就是要构建一个非常强壮的设计。能够将问题层层分类解决。是的，当问题复杂到一定程度之后，虽然我们通常的理解是一步到位会快些，但是事实往往分层更容易开发，维护，管理和甚至是优化。如果不分层，那么想象，搞这么多信息，还需要能支持用户扩展，而且，这个异常处理充斥整个系统本身设计。MS如何能够协同那么多人开发，即使都是天才？</li>
</ul>


<p>整个NT处理异常就是这样的，异常来了，OS先找debugger，debugger不管，那就在程序堆栈上找人，也不管，唉，debugger你还不管？ 好吧，subsystem你搞定吧。对于这种谁都不管的异常，正式一点的叫法是未处理异常，这个也其实是比较复杂的，因为2K， XP，vista的策略都不同。策略本身不复杂但为什么不同？ 有机会的话，需要再深入一点学习一点。</p>

<p>这里面对大多数同学，如果不了解汇编的话，可能无法理解这个调试器为什么要跑2次？要知道我们现在可是在和效率赛跑，而且为什么调试器首先要捕获异常？而不是我们本身的程序？</p>

<p>我们想一个问题。在我们使用debugger调试程序的时候，我们的程序凭什么能够加入断点，然后停下来？CPU执行可是老老实实的按照一条条的指令跑的，没有那些花花肠子。当我们单步调试的时候，为什么程序执行一条指令（我这里指调试汇编代码，调试c，c++这些还需要稍微麻烦一点）就要停下来呢？当我们有了中断的概念就不难理解这个问题了。是的。就是发生了中断。导致CPU暂停了当前被调试进程，而把控制流转向到了debugger。那么怎么暂停？为什么能够暂停？这个还是交给OS的调度和同步那里再学习吧。</p>

<p>事实上，这个断点（我说的这种）就是指令INT 3。他可以说是我们非常熟悉，但又陌生的。不知道大家在一开始用c编程的时候，至少是我自己，在辛苦了半天之后，一运行发现屏幕上跑出一大堆烫烫烫烫。事实上，他就是INT 3。</p>

<p>INT 3的机器码是1100 1100b（0xCC）。一个字节长。编译器在debug下会给我们创建额外的栈空间并填上INT 3，至于为什么这样，我这里就不啰嗦了。这种纯菜鸟错误，通常是没把指针玩明白。有点远，呵呵，为什么扯这么远，是因为在有了之前的硬件知识，这里很可能产生疑问。看这个指令的样子，我们发现他是个软中断，或称为trap。那么根据之前所讲的，这里的异常地址应该是这条指令的下一条。但是我们这里看到的却是我们打断点的这条指令。那么要搞清楚这个，又要稍微绕绕下。当我们加入一个断点的时候，vc会自动记录下我们这个断点的位置信息。当调试的时候，vc会把这些断点位置处的指令换成我们的INT 3。也就是替换掉一个字节。当然，替换之前要保存原来的。这个过程叫做落实断点（resolve break point）。那么当CPU执行到INT 3指令时。是的。这时我们就明白了，为什么要先让调试器捕获异常了。这些东西要是先给了我们做，那么调试器就没法子实现功能了。然后就是一系列的硬件，OS的事情。vc把之前我们的代码再恢复过来。所以这也就是RtlRaiseException产生的软件异常并不会先扔给debugger first chance。因为我们自己搞得东西是不可能和debugger有任何关系的。</p>

<p>我们这里需要特别关注下NT干的事。</p>

<p>对于NT来说，INT 3 会导致CPU执行KiTrap03程序。（为什么执行这个，我们在IO那里再了解）。在WRK中，我们可以看到这部分的源代码。这里不得不提MS，不知道哪个脑子别了改锥的人想出了一个这么限定，代码不能超过50行。无语。</p>

<pre><code>mov     esi, ecx                ; ExceptionInfo 2
mov     edi, edx                ; ExceptionInfo 3
mov     edx, eax                ; ExceptionInfo 1

mov     ebx, [ebp]+TsEip
dec     ebx                     ; (ebx)-&gt; int3 instruction
mov     ecx, 3
mov     eax, STATUS_BREAKPOINT
call    CommonDispatchException ; Never return
</code></pre>

<p>不管怎么说，人家总是做出贡献了。我们看到了dec ebx。是的。在处理异常的时候，nt这里修正了一下，而那个1，就是INT 3这条指令的长度。现在我们就明白为什么我们能正确看到我们的代码了。也验证了trap的流程。</p>

<p>绕了很远，把思路拉回来。</p>

<p>让我们再思考一个问题，程序流程突然转变了，甚至可能永远回不来了，而且我们现在的代码是看不出这个状态。也就是我们随时都可能被别人抢了。哎，可惜啊，咱们处在最底层。人为刀俎，我为鱼肉。但是NT还是比较有人性的。而且这也是很有必要的。在程序流程突然转变了。在保护的这段代码中，可能有一些关键的操作没有做。比如内存释放，一些同步的锁等。但是由于某种未知原因，我们只能放弃这部分操作。那么我们的这部分被动代码什么时候执行呢？而且，由于这些保护的代码很可能由于函数调用，在形式上或是非形式上，都可以形成一个嵌套的关系。这些释放的顺序，从那里开始释放，释放到哪里？这都是NT需要给我们规划好的。</p>

<p>不要被我复杂的言论迷惑，实际上整个过程很简单。因为我们程序的执行流程信息都在堆栈上。我们根据堆栈信息我们可以很容易找到起点和终点。那么从问题出发点，到结束点。我们便走了2次。第一次从出发点到结束点，这是为了找到处理程序。第二次则是叫做stack unwind，栈展开。 从出发点到结束点。当然这个过程中，依然有很多更复杂的问题。异常查找时很可能产生死循环。unwind的过程也可以被随时中断或是走到其他地方。而导致我们写的那些备用代码无法执行。事实上NT给了我们非常多的选择。vc只是披了一层皮。</p>

<p>SEH就像ReactOS上写的一样，“SEH is a game which is played between OS and Compiler (Keywords: <strong>try, </strong>except, __finally)。</p>

<p>写在最后</p>

<p>我发现我越来越罗嗦了。絮叨絮叨的像个大妈。
后面的部分依然有点穿越。在不谈具体实现的细节下去说清楚SEH的基本过程，对我还是太复杂了，应该是我还没有理解透彻，慢慢来吧。具体过程可以参考我推荐的3篇文章，当然。最好的方法是自己推导。
我真的不知道这篇文章是写给自己还是写给别人看的。是的。如果我是读者，当我看到这篇文章的时候，我真想向这个作者扔砖头。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[胡言乱语计算机一]]></title>
    <link href="http://studentdeng.github.com/blog/2011/01/22/computer1/"/>
    <updated>2011-01-22T22:51:00+08:00</updated>
    <id>http://studentdeng.github.com/blog/2011/01/22/computer1</id>
    <content type="html"><![CDATA[<p>操作系统是连接硬件和应用软件之间的纽带。至少目前是这样的。而操作系统这门课也是计算机专业的必修课之一。无奈当时混沌。并没有真正的上好这一门课，之所以叫胡言乱语。是因为这里面的水对我来说实在是太深了。任何一个小的问题背后都是一个深渊。所以第一篇，从最初的（大学课程最初）开始讲起。</p>

<p>8086，应该是学计算机最开始的地方。可以说是我们现在x86系列的最简单，最基础的实现。里面的设计都或多或少的影响到了后面系列的实现。所以，学校从这里开始，的确是非常明智的，虽然当时我不这么认为。但是想要了解或是明白8086的设计，那么也就要带出另外的那些更为底层的，计算机指令集，机器语言，引脚，门，电压等等。当然我不是说这些不重要，但是如果有这些基础，的确可以加快，加深8086以及其他系列的一些知识的理解。这里就略过这些东西。一是自己能力不足，二是我觉得现在谈这个真的不是很重要。想想，这2个原因其实也就一个 ：)。</p>

<p>存储器是计算机的核心部件。现在的计算机围绕存储器来构建，所以必须从存储器开始。</p>

<p>在CPU眼中，存储器保存的东东。只有2种：指令和数据。当然退而求其次，存储器中没有指令和数据之分，只有0和1。这个世界的确是非常的和谐简单。那么CPU是如何分别这2种东东呢。这完全取决于CPU自己。当遇到二进制信息如1000100111011000时，CPU可以把他看成大小为89D8H的数据处理，也可以看做是指令mov ax bx来执行。</p>

<p>存储器被划分为若干个存储单元，一般来说，一个存储单元大小为一个Byte。一个拥有128个存储单元的存储器。容量为128个字节。</p>

<p>那么存储器被划分为了多个存储单元，从0开始排序。CPU从内存中读取数据，首先需要的就是存储单元的地址，也就是CPU需要知道读取哪一个存储单元中数据。当然CPU不仅仅需要知道地址，还需要告诉存储器要做什么操作，是读还是写？而且在计算机中，也不仅仅只有一个存储器，也不仅仅只有一种设备需要去操作。还需要指明对哪一个设备操作。所以。CPU对数据的读写，需要以下的基本信息。</p>

<p>存储单元地址（地址）
设备选择，读写命令（控制）
读写的数据（数据）
那么CPU通过什么来将这些信息传递给设备呢？CPU计算机中的这些设备处理传输信息都是电信号,连接这些设备的导线为总线。总线根据传送信息不同，分为地址总线，控制总线，数据总线。</p>

<p>CPU从3号单元中读取数据过程：</p>

<p><img src="/images/computer-1.png" alt="alt text" /></p>

<p>CPU通过地址线将地址信息3发出
CPU通过控制线发出读命令，选中存储器，通知到读数据
将3号单元中的数据8通过数据线交给CPU
既然知道了CPU读取数据的流程，那么CPU能够找到多少个这样的地址是我们遇到的下面的问题。显然，地址总线上能传递多少种不同的地址，那么CPU就可以找到多少个存储单元的地址。</p>

<p>如果CPU有10根地址总线，1根能够提供2种信号：1、0。那么10根就能提供2<sup>10个，也就是1024种。那么我们就说CPU的寻址大小为1K。或这个CPU的地址空间为1K。</sup></p>

<p>CPU与各个设备之间传递数据是通过数据总线进行。所以，数据总线的宽度决定了CPU和外界数据传递的速度。我们很容易想到16根数据线可以一次传递2个字节。</p>

<p>同样类似的。控制总线的宽度，也决定了CPU对外部的控制种类。所以，决定了CPU对外部的控制能力。</p>

<p>当我们买电脑的时候。除了考虑CPU以外，还需要搞定一个好的主板。当我们打开电脑之后，看到的首先也是这个大家伙。而且如果你的电脑主板被烧坏的话，那么基本上这个电脑主机也就完蛋了。可见主板在现在计算机中的地位。</p>

<p>主板最基本的作用就是通过它把计算机的核心部分通过总线（地址、控制、数据总线）相连，并且还需要为扩展预留接口。当我们买到一个主板时，会看到有非常多的接口卡槽，而事实上CPU控制这些设备就是通过总线去控制这些接口卡来进行的。</p>

<p><img src="/images/computer-2.png" alt="alt text" /></p>

<p>上面的那些东东，不管是显卡，声卡，网卡。都有两点相同。</p>

<p>都和CPU总线相连
CPU进行读写操作是，都是通过控制线发出内存读写命令。
也就是说，CPU操作他们的时候，都把他们当做内存来对待。把这些不同的设备组成一个大的逻辑存储器。这个逻辑存储器就是我们的地址空间。</p>

<p><img src="/images/computer-10.png" alt="alt text" /></p>

<p>在上面这个图中，所有的物理存储器都被看作一个由许多存储单元构成的逻辑存储器，每一个都有一个地址段，也就是一段地址空间。CPU往这段空间中读写数据，其实就是读写了物理存储器。</p>

<p>那么我们可以看出。CPU的地址总线宽度是在是太重要了。在我们的8086中，地址总线宽度为20，也就是可以搞定2<sup>20个不同的地址。也就是说8086的地址空间大小为1MB。</sup></p>

<p>不同的计算机系统，的地址空间分配是不同的。如下是8086的</p>

<p><img src="/images/computer-3.png" alt="alt text" /></p>

<p>看到这幅图，那么我们就可以从容的写一个HelloWorld程序输出到我们的屏幕上。</p>

<p>因为我们可以直接在A0000~BFFFF中写数据，而这些数据会跑到显卡中最后跑到屏幕上。</p>

<p>那么我们现在明白了。CPU访问内存单元时，需要给出这个内存单元的地址，所有的内存单元构成存储空间是一个一维线性空间。每一个内存单元在这个空间中都有唯一地址，这个唯一的地址，就是物理地址。</p>

<p>CPU通过地址总线送入存储器的。必须是一个内存单元的物理地址。同样，这个地址在CPU内部中必须搞定这个地址，再发送到地址总线之前。不同的CPU形成物理地址的方式也不同。而我们现在所考虑的就是8086是如何搞定这个物理地址的。</p>

<p>那么我们又必须要了解些其他知识。8086是16位结构的CPU。那么他的意思是</p>

<p>运算器一次最多处理16为数据
寄存器最大宽度16位
寄存器和运算器之间的内部线为16位。
也就是说，8086一次只能处理，传输，存储（寄存器）16位的地址。从我们大多数人的思维，一个地址，也就是一个指针，最好和一个整数的长度一致。但是，我们知道8086的地址总线为20位。达到了1MB的寻址。为什么会是这样的呢？在很久很久以前，当CPU的技术从8位发展到16位的时候，地址总线本来也应该是16位，也就是64K。但是大家发现这个太小了。然后intel决定采用1M。这个在当时，的确是非常的大，而盖茨甚至还有“无论对谁来说,640K内存都足够了”的言论。当然。这里并没有不敬在里面。只能说，计算机的发展实在是太迅速了。所以，地址总线的宽度为20位。但是这个带来了一个问题。面对16位的ALU，如何来填补这个呢？</p>

<p>Intel设计了一种在当时看来一个非常巧妙的方法。也就有了我们现在看到的8086地址翻译。16位段地址+16位偏移来形成这个20位的地址。</p>

<p>随着计算机的发展，我们越来越的希望计算机能够处理更多的事情，伴随着CPU运算能力的提升。整个计算机的性能主要是卡在了CPU利用率上。面对“优秀”的CPU，我们并没有充分的利用它实在是暴殄天物。所以我们希望我们的CPU能够给我们做更多的事情，最好不要停。就像老早的资本家总是希望工人天天干活一样。</p>

<p>不幸的是，在当时的DOS操作系统下面。是单任务的。并不支持多任务。我们不能在听音乐的时候打开文本文档编辑。那么，构造计算机的那些老前辈们，想到的一个招数是时间片。每个程序都有机会获得这些时间片，通过不断的轮询，只要这个时间足够短，那么人类是无法觉察出来。我们会有这个错觉，好多的程序再一起执行。</p>

<p>虽然我们在DOS可以利用内存驻留的技术实现类似的体验，但是这个却并不是安全的。因为我们往往是通过修改中断向量表来做。我们无法保证其他程序是否正确修改中断向量表。而且如果我们的程序通过这里修改，并成为我们程序的一部分时，也就意味着，其他的程序也能这么做。那么我们很难保证计算机中的各个程序能够互不影响。同样，包括操作系统。这也就意味着我们无法构建一个安全的环境，让我们的操作系统，以及各个程序不互相影响，制约。</p>

<p>同样，当我们将CPU时间片分给那些程序的时候。在一开始的初期，并不是我们这样的多任务。而是一种叫做协作式多任务。操作系统控制CPU的时间片，而每个程序形成一个队列。每个程序在获得CPU时间后必须归还CPU。注意，这里的归还是程序本身的事情，而不是操作系统的事情。也就是说，如果有一个程序不想归还时间片，或是他不小心陷入一个死循环，那么别的程序也就无法执行，甚至包括操作系统自己本身。因为他自己也在那个队列里面傻等。那么这整个世界也就变得混沌不堪了。因为操作系统，并不能识别哪一个程序是不良的程序。</p>

<p>造成这些问题的根本原因在于，我们并没有等级的概念。也就是说，整个硬件资源对我们的每一个程序都是平等的。事实上8086下我们看到了任何一个程序，都可以通过段+偏移来实现访问整个地址空间。甚至是中断向量表还有硬件。所以，在这个原始社会下。我们达到了真正意义上的公平，但是也验证了低下生产力的现实。</p>

<p>所以，为了实现这些功能。必须有硬件的支持。那么80386也就跳入了我们的视野。事实上，他就是为了支持我们的想法（实现多任务，实现各个任务互不影响）而诞生的。</p>

<p>在开始介绍80386之前。我们好好思考一下我们需要实现的功能。</p>

<p>实现等级观念，有些程序需要有特权。执行一些系统的核心部分，而一些程序必须在一些限制上运行。具体的讲则是有些地址空间不能访问，有些寄存器不能读取或是修改。
需要提供一个复杂的内存管理，来帮助我们实现各个任务的独立的地址空间。这样可以保证一个任务不会随意修改另一个任务的数据。
其实，让我们说到根上。其实我们需要实现针对地址空间的保护。只有实现了这种保护机制，我们才能保护操作系统的代码，维护操作系统的特权。而有了操作系统的支持下，我们才能继续去谈内存管理，和保护操作系统之上的各种程序之间不互相影响。搞定了这些之后，我们就不难理解8086的缺陷以及80386为什么要实现这些功能了。当然。这个过程肯定不会像8086那样平滑。因为这完全是一个不同的设计思路，思想。即使，他披着一张似乎有着段加偏移量的一层皮。</p>

<p>好吧，让我扯的远一点。随着生产力的发展，有一个超牛B的程序，他想做其他程序的老大。让他们乖乖听话。而这个程序，就是操作系统。可惜啊，在原始社会，生产力不足。并不能让所有的人都听话。让我们暂时告别原始社会，我们来到了奴隶社会。其实计算机发展也和人类社会一样。我们出现了阶级，让我们仔细看看这个维持统治阶级工具的核心——80386体系结构。</p>

<p>80386以后，CPU历经多种改进，虽然速度提高了几个量级，功能上也有很多改进。但并没有重大的质的改变。所以统称为i386结构，如果除去大量的3D密集型图形图像运算，并行等之后。其实，只是相当于一个更更快速80386而已。</p>

<p>80386是32位的CPU。也就是ALU数据总线是32位。这里，我们终于在地址总线和数据总线一致了。都是32位。当面对地址总线的宽度达到32位。也就是CPU的寻址能力达到了2<sup>32</sup> = 4G。这的确是一个相当大的空间。为了保证这个空间的和谐。80386增加了一个叫做保护模式的一个名词。但是为了和之前的8086体系兼容，又有了实模式和虚拟86模式。</p>

<p>这里只是简单的介绍。实模式，没有什么其他的意义。只是比原来的8086寄存器大了。CPU快了。一些指令和操作更加方便容易了。</p>

<p>保护模式则是重点。事实上，没有保护模式，现代操作系统是无法构建的，在x86下。</p>

<p>既然我们有了这么大的一个空间，那么该如何分配呢？很容易的想法是，我们可以把地址空间平均分给各个任务。那么他们都有了各自的地址，他们只要在各自地方做就好了。但是这个同样假设这各个程序都是善良的。而且，对于各种各样的硬件又该如何做呢？他们所映射的CPU地址空间该如何保护？而且，当我们真正的运行着相当多的任务的时候，我们的内存，是否还能经得住呢？而这些问题归根到底是因为CPU的地址空间每一个任务都是可见的，那么就想通过各种各样的渠道来搞破坏。所以，为了构建操作系统的核心地位，以及各个任务之间的互不干涉。操作系统中最重要的概念登场了——虚拟存储技术。</p>

<p>其实，这是一个很简单的道理。统治阶级（操作系统）为了维持他的权威，他把珍贵的核心资源（CPU地址空间）和被统治阶级（用户程序）之间加了一个中间层，从而核心资源（CPU地址空间）对被统治阶级（用户程序）是透明的而统治阶级（操作系统）所独占。然后他又对所有的被统治阶级（用户程序）整了一个弥天大谎:“你们有整个4G的CPU地址空间。而且你们在跑的时候（程序运行）是独占所有资源的”。然后被统治阶级（用户程序）就在这个统治阶级（操作系统）下勾画的这个美丽的世界下安分的生活下去了，至少是绝大多数。（这里的表达不准确，这里的用户程序，其实我的意思是任务，或是说，在普通程序，我们可以写这么一个地址，在高地址空间上，只是如果我们去操作他，操作系统不让我们这么做。但是我们还是能“看”到的。感觉还是不合适，这段可以去掉：)）</p>

<p>OK。操作系统给这个世界整个一个这么大的谎言。现在计算机的核心资源都在他的掌握下了，他的目的终于达到了。但是就和再苛刻的资本家也得给工人发工资一样。如果没有了被统治阶级，统治阶级还有什么存在意义呢？所以，操作系统也必须给用户程序一个高效的获得CPU资源的方式。也就是要给用户程序发工资。</p>

<p>而一个程序运行的最基本的要求就是数据。瞎话扯了这么多。该来点正经东东了。</p>

<p>80386CPU的内存管理支持2种，段式，和段页式。这些都为操作系统实现内存管理提供了硬件基础。</p>

<p>CPU的段机制，提供了一种手段。可以将系统的内存空间分成一个个较少的受保护区域。每个区域称为一个段。每个段都有自己的基地址，边界和访问权限。但是80386在实现这个的时候，不得不背上历史的负担。intel选择了在原有段寄存器的基础上构筑保护模式。并保留了原来的16位段寄存器。并添加了2个段寄存器FS,GS。但是我们看到了。光是用段寄存器来确定一个地址是不行的。因为我们需要这个地址段的长度（边界），访问权限等等。所以，这里变成了一个数据结构，而不是之前8086的那个单纯的基地址。</p>

<p>所以，intel在做这个的时候，改变了段寄存器的功能，使他从单一的基地址，改成了指向一个数据结构的地址（或是数据结构的指针可能好听点）。这样，CPU才能获得它足够的信息。而这，也是学过8086 再看80386最让人迷惑的地方。因为这个完全是2套东东。而且根本上没有任何关系。</p>

<p>让我们捋一下当一条访问内存指令的执行情况。</p>

<p>根据指令的性质确定使用哪一个段寄存器。
根据段寄存器内容，找到相应的段描述符结构。
找到基地址。
将指令中的发出的地址位移，检查是否越界。
根据指令的性质和段描述符中的访问权限看时候越权。
一切正常，我们相加获得实际物理地址。
CPU搞定段需要知道3个信息。</p>

<p>段基地址
段界限
段属性
段信息的长度是64位。段基地址32位。段界限20位，段属性12位。而这个段信息标准的叫法就是段描述符。而许许多多的段描述符组成个段描述符表。</p>

<p>为了能够访问段描述符表，80386中新增了2个寄存器来寻址段描述符表：GDTR和LDTR。GDTR为全局描述符表寄存器，LDTR为局部描述符表寄存器。GDTR是48位，直接指向内存的线性地址，32位的线性基地址，16位的边界描述这个表的大小。LDTR是16位寄存器，表示的是全局描述符表的索引。这说明LDT其实就是GDT中的一项而已。</p>

<p>段寄存器中的内容为16位。由于指向的内容改变了。所以也有了新的名字，为段选择子。</p>

<p><img src="/images/computer-4.png" alt="alt text" /></p>

<p>TI表示要索引的段描述表种类。TI = 0表示全局描述符表，TI = 1表示局部描述符表。由于索引只有13位，也就是说，我们的表项最多2<sup>13</sup> = 8K个描述符。RPL 表示请求特权级，用于特权检查。</p>

<p>我们现在仔细看看这个索引指向的内容，描述符表。</p>

<p>在一个多任务系统中。通常我们会同时存在很多个任务，每个任务涉及多个段，每个段都需要存放段描述符。那么描述符根据用途不同，IA-32处理器分为3种描述符表。全局描述符表GDT，局部描述符表LDT。中断描述符表IDT。IDT将放在后面中讨论。段描述符的结构比较纠结，充分体现了历史负担。这里也就不继续了，不过，这个真是一个相当“太监”的结构。</p>

<p>GDT表是全局的。一个系统中通常只有一个GDT。供所有任务使用。LDT和具体任务相关，每个任务都可以有一个LDT。也可以多个任务共享一个LDT。</p>

<p><img src="/images/computer-5.png" alt="alt text" /></p>

<p>根据上图，我们可以形象的看出，段内存管理的计算方式。讲了这么多的理论，让我们稍微动动手。</p>

<p>使用Windbg调试程序，可以使用dg命令来显示一个段选择子指向的段描述符详细信息。首先看下CS</p>

<p><img src="/images/computer-6.png" alt="alt text" /></p>

<p>Sel就是选择子（selector）。base limit就是之前的基地址，和边界。Code就是段的类型。RE = ReadOnly + Executable。Ac表示访问过</p>

<p>Pl表示特权级别（Privilege Level）。3的意思是用户特权。Size表示代码的长度，Bg意味32位代码。Gran表示粒度 Pg代表为内存页4K。Pres代表是否在内存中（我们之前看到了那么多的表项，8K，事实上并不是都在内存中的，当不在内存中时，访问会重新载入这个内容，所以需要记录）。Long 下的Nl表示 这个不是64位代码。</p>

<p>我们看到了SS DS ES 一样。</p>

<p><img src="/images/computer-7.png" alt="alt text" /></p>

<p>我们看到了类型是数据，并可以读写。而且我们发现。SS DS ES CS 的基地址都为0，长度都是整个内存空间大小。Intel把这种方式成为平坦模式（Flat）。我们看到了当我们通过段+偏移获得一个地址，其实基地址的作用已经没有了。limit也是最大空间4G，作用也很小了。可见，在平坦模式下，只是段管理的一个特例。我们只是关注与权限而已。</p>

<p>等等，少了一个。FS这个段寄存器比较特殊这里只是贴个图。具体的会在后面总结他。当然这里面的知识非常多，还有各种各样的段描述符存在。但是如果是和我一样在这些方面是新手，我觉得还是知道的少一点比较好。</p>

<p><img src="/images/computer-8.png" alt="alt text" /></p>

<p>我们看出，根据段内存管理下。我们把程序分成了不同类型。有代码部分，有数据部分等。但事实上，无论是windows 还是linux都没有采用段内存管理，准确说是只使用Flat模式,也就说。只是使用了权限部分来针对特权级对代码和数据保护。</p>

<p>Intel在80286实现保护模式，段式内存管理。但是发现了如果不支持页式管理是不行的。所以，在80386下，需要支持页式管理。也就是说，80386又背起了历史的负担，既要维护段式管理，还要实现页式管理。</p>

<p>之前的段式管理机制，是通过段寄存器转换加偏移形成一个32位的物理地址。这个是真正的物理地址，也就是这个是要在地址总线上跑的。也就是说应用程序获得的这个地址是真实的地址，那么也就对操作系统对内存换入换出增大了困难。而且对需要对code和data分类管理，导致程序加载过慢。而且缺乏足够的对内存管理的粒度，而究其原因，就在于它并没有真正的隔离用户程序和实际资源以及等等问题。所以，页式管理开始登场了。</p>

<p>本来页式管理和段式管理是不需要结合在一起的。但是在80386中。保护模式的实现是和段式管理分不开的（权限控制）。我们在查看CS的代码段描述符时，我们看出执行的这段代码的优先级是3。所以intel设计80386时，就考虑利用原有的基础再扩充。那么也就有了我们现在的基于段式管理的页式管理。也就意味着，我们需要在段式管理上再建立一个地址映射。说白了就是。这整个一套地址转译，需要将逻辑地址，通过段式管理转成线性地址，再通过页式管理最终转成真实的物理地址。那么如果我们启用了页式管理，那么段式管理的运行结果就不是之前的真实的物理地址，而成了一个中间地址或是线性地址。而这个过程。同样也是从8086跳到80386比较费劲的地方。</p>

<p>80386将线性地址空间划分为4KByte的页面（一般情况下）。每个页面可以被映射至物理存储空间中任意一块4KByte大小的区间。在段式管理下，连续的逻辑地址转译后在线性地址空间还是连续的。页式管理下物理空间却可以不连续。所以我们可控的粒度更小，从而更灵活。而物理空间的不连续，也就意味着我们可以更加灵活的把暂时不用的数据放到外部存储器，通常为硬盘。而这也就解决了我们多任务下，物理内存不够的情况。</p>

<p>当然，灵活的背后便是复杂的机制，在我们继续了解详细的页式管理过程之前。我们先看一下我们真正的需求，以及80386给我们提供了什么。</p>

<p>我们的首先目的是特权机制。通过特权机制来保证操作系统的权威。也就是一些指令，寄存器只能由操作系统这一级别的才能操作。而用户程序不能操作。这是段式管理已经搞定的。那么剩下的问题就是用户程序和用户程序之间互不影响。</p>

<p>在页式管理中，我们已经有了一个虚拟层：线性地址。事实上。每一个任务都有一个这样的虚拟地址。任务中针对地址的操作都是在这个虚拟地址上而不是真正的物理地址。我们知道。我们的数据最终和物理地址相关联才有意义。这个中间层，使得任务不知道自己确切的物理地址，也就为了保证一个任务不会被另一个任务随意修改或访问。</p>

<p>80386页式管理的核心是将线性地址空间划分成一个个页面，大小一般为4K。那么我们需要保存这一个个页面的映射关系。而我们知道，现在的地址空间大小是4G。那么我们剩下的就是如何管理，或是保存这些信息。我们首先发现，这个空间对我们绝大多数程序来说都太大了。所以为了减少保存这些映射的资源，80386使用了分级管理，所以，一个简单的线性地址被拆成了3个部分。</p>

<p><img src="/images/computer-9.png" alt="alt text" /></p>

<p>分别为Directory， Table 和Offset。</p>

<p>对于一般来说，页面大小为4K。为了能够找到每一个Byte，那么我们需要12位才能找到。也就是Offset = 12的原因。</p>

<p>我们称指向一个页面的地址（指针）为页表项，多个页表项的集合构成页表。10位table，也就意味着我们能够表示1K个pageTableEntry。那么我们总共能够表示的4MByte。</p>

<p>指向页表的地址（指针）为页目录项。多个页目录项的集合构成页目录。10位的Directory，也就意味着我们能够表示1K个Directory entry。那么我们总共能够表示4GByte。正好为我们的地址空间大小。</p>

<p>CR3寄存器，则给我们指出了Directory 的基地址。所以它又有了另一个名字，页目录基地址寄存器（PDBR）。</p>

<p>具体的取址这里就不描述了。因为上图已经很清楚了。</p>

<p>这真是一个看似完美的方案。但是现实是很残酷的。我们并没有那么多的内存。为了能够跑起那么多的程序，支持多任务，也就是意味着，我们需要在一些时候，把一些内存搬到硬盘。那么当我们访问这些页面的时候，就会产生pagefault，然后操作系统会把这部分页面再搬入到内存中。</p>

<p>当然，还有相当多的细节这里无法阐述。事实上，我们也不可能一下子把这些东东搞清楚，毕竟这些东西离我们还是有些远。下一篇将从应用的层面扯。当然在合适的时机，我们还需要回来。比如另一些重要的概念如中断。</p>
]]></content>
  </entry>
  
</feed>
